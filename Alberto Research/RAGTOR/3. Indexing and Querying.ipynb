{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_md_to_text.txt\", \"r\", encoding=\"latin-1\") as f: # TO DO: check proper encoding for .md files\n",
    "    markdown_example = f.read()\n",
    "\n",
    "with open(\"example.pdf\", \"rb\") as f:\n",
    "    pdf = f.read()\n",
    "\n",
    "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
    "    hf_token = f.read()\n",
    "\n",
    "with open(\"GROQ_KEY.txt\", \"r\") as f:\n",
    "    groq_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alberto-lorente\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder, whoami\n",
    "\n",
    "HfFolder.save_token(hf_token)\n",
    "print(whoami()[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda available\")\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"example.pdf\"\n",
    "\n",
    "base_prompt=\"\"\"CONTEXTE\n",
    "L'image suivante contient une page et un tableau. \n",
    "\n",
    "TÂCHE\n",
    "Décrivez le tableau et le contenu de la page en accordant une attention particulière au contexte qui l'entoure, qu'il s'agisse de budgets, de dates, d'élections, d'agendas, de projets futurs ou de sujets connexes. \n",
    "\n",
    "FORMAT DE LA RÉPONSE\n",
    "Votre réponse doit être aussi détaillée que possible. \n",
    "Votre résultat doit être la description du tableau directement.\n",
    "La langue de votre réponse est le français\"\"\"\n",
    "\n",
    "\n",
    "summary_prompt = \"\"\"Il s'agit d'un texte concernant un projet de géothermie :\n",
    "TEXTE: \n",
    "{}\n",
    "\n",
    "TÂCHE:\n",
    "Make a one page summary paying special attention to all the administrative matters like budgets, plans, actions to take in the future, organizational and hierarchical charts, announcements, meetings, contacts, elections, reports and all the related topics to these.\n",
    "\n",
    "OUTPUT:\n",
    "Publier directement le résumé.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council_rag.preprocessing import preprocess_markdown_text\n",
    "from council_rag.data_transformations import process_tables, summarize_clusters\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "paragraphs_list, clusters_dict = preprocess_markdown_text(markdown_example,\n",
    "                                                        model_id =\"HIT-TMG/KaLM-embedding-multilingual-mini-v1\", \n",
    "                                                        spacy_model=\"fr_core_news_sm\", \n",
    "                                                        n_sents_per_para=10,\n",
    "                                                        device=device)\n",
    "\n",
    "processed_tables = process_tables(pdf_path, \n",
    "                                base_prompt, \n",
    "                                groq_token)\n",
    "\n",
    "clusters_dict = summarize_clusters(clusters_dict, \n",
    "                                    summary_prompt, \n",
    "                                    groq_token, \n",
    "                                    model=\"gemma2-9b-it\", \n",
    "                                    token_limit=14000, \n",
    "                                    sleep_time=60)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1801420529683435\n"
     ]
    }
   ],
   "source": [
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing time so far is around 4 minutes and a half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we are going to query are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraphs_dict \n",
    "# processed_tables\n",
    "# clusters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting some info that we won't need and turning the cluster dict into a list to match the paragraphs list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del paragraphs_list[0][\"para_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_list = list(clusters_dict.values())\n",
    "i = 0\n",
    "while i < len(clusters_list):\n",
    "    clusters_list[i][\"cluster\"] = i\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the embedding model and setting up the index and vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the embedding to pass it to the index\n",
    "shape_emb = embedding_model.encode(\"Hello World!\")\n",
    "emd_dims =  shape_emb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# init the intex\n",
    "index = faiss.IndexFlatL2(emd_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# creating the vector store\n",
    "vector_store = FAISS(embedding_model, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['para_indexes', 'union_paras', 'cluster_summary', 'cluster'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_list[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing all the information we have collected so far into Document objects that will be fed into the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paras = [] # to process into smaller chunks\n",
    "cluster_summ_docs = [] # filled with the cluster summaries langchain doc type\n",
    "\n",
    "for cluster in clusters_list:\n",
    "    \n",
    "    cluster_para = cluster[\"union_paras\"]\n",
    "    cluster_summ = cluster[\"cluster_summary\"]\n",
    "    \n",
    "    cluster_paras.append(cluster_para)\n",
    "    cluster_summ_docs.append(Document(page_content=cluster_summ, metadata={\"cluster\": cluster[\"cluster\"],\n",
    "                                                                            \"type\": \"summary\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=450, \n",
    "                                        chunk_overlap=35,\n",
    "                                        length_function=len,\n",
    "                                        is_separator_regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paras_docs = []\n",
    "for cluster_union in cluster_paras:\n",
    "    cluster_union_docs = splitter.split_text(cluster_union)\n",
    "    cluster_paras_docs.append(cluster_union_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_paras_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_chunks = []\n",
    "i = 0\n",
    "while i < len(cluster_paras_docs):  \n",
    "    curr_cluster = cluster_paras_docs[i]\n",
    "    for cluster_chunk in curr_cluster:\n",
    "        cluster_chunks.append(Document(page_content=cluster_chunk, metadata={\"cluster\": i,\n",
    "                                                                                \"type\": \"cluster_chunk\"}))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=[\"### **Page 1 sur 49**\\n...du 1er septembre 2021.\"], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m augmented_table_chunks\u001b[38;5;241m.\u001b[39mappend(Document(page_content\u001b[38;5;241m=\u001b[39maugmented_chunk, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maugmented_table\u001b[39m\u001b[38;5;124m\"\u001b[39m}))\n\u001b[0;32m      9\u001b[0m description_chunk \u001b[38;5;241m=\u001b[39m table[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_context\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m table_descriptions_chunks\u001b[38;5;241m.\u001b[39mappend(\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m html_chunk \u001b[38;5;241m=\u001b[39m table[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_html\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m html_tables_chunks\u001b[38;5;241m.\u001b[39mappend(Document(page_content\u001b[38;5;241m=\u001b[39mhtml_chunk, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml_table\u001b[39m\u001b[38;5;124m\"\u001b[39m}))\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\documents\\base.py:285\u001b[0m, in \u001b[0;36mDocument.__init__\u001b[1;34m(self, page_content, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Pass page_content in as positional or named arg.\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# my-py is complaining that page_content is not defined on the base class.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Here, we're relying on pydantic base class to handle the validation.\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=[\"### **Page 1 sur 49**\\n...du 1er septembre 2021.\"], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": [
    "augmented_table_chunks = []\n",
    "table_descriptions_chunks = []\n",
    "html_tables_chunks = []\n",
    "\n",
    "for table in processed_tables:\n",
    "    augmented_chunk = table[\"table_augmented_context\"]\n",
    "    augmented_table_chunks.append(Document(page_content=augmented_chunk, metadata={\"type\": \"augmented_table\"}))\n",
    "    \n",
    "    description_chunk = table[\"table_context\"]\n",
    "    table_descriptions_chunks.append(Document(page_content=description_chunk, metadata={\"type\": \"description_table\"}))\n",
    "    \n",
    "    html_chunk = table[\"table_html\"]\n",
    "    html_tables_chunks.append(Document(page_content=html_chunk, metadata={\"type\": \"html_table\"}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we have:\n",
    "\n",
    "- The individual text chunks.\n",
    "- The clusters summaries chunks.\n",
    "- The augmented table chunks.\n",
    "- The table descriptions chunks.\n",
    "- The html tables chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'cluster': 0, 'type': 'cluster_chunk'}, page_content=\"PROCES VERBAL\\n\\n\\n\\n L'an deux mille vingt et un, le 28 octobre à 18 h 00, les conseillers communautaires de Roannais Agglomération, se sont réunis à l\\x92Espace Chorum \\x96 Halle Vacheresse \\x96 Rue des Vernes à Roanne.\\n\\n\\n\\n La convocation de tous les conseillers a été faite le 22 octobre 2021, dans les formes et délais prescrits par la loi, par Yves Nicolin, Président.\\n\\n\\n\\n # Etaient présents :\")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'cluster': 0, 'type': 'summary'}, page_content='The provided text describes the proceedings of a meeting of the Roannais Agglomeration (likely a French \"agglomération\"  is a type of metropolitan or urban agglomeration. **The documents appear to be minutes of a meeting of Roannais agglomération.  **\\n\\n\\nThe document is a record of a meeting of the  of Roannais Agglomeration\\n\\n\\nPlease provide the full text!\\n\\n\\n## Summary of proceedings of  Roannais Agglomè\\n\\nThe document is a record of a meeting \\n\\nThe document is a record of a meeting\\n\\nThe document is a record of a \\n\\n\\n## Summary of  \\n\\n### Budget \\n\\n\\n## Administrative Matters\\n\\n\\nHere is a summary of the  \\n- Budget General\\n\\n\\nHere\\'\\n\\n\\nThis document appears to be a record of a meeting \\n___\\n\\nPlease provide the full text  \\n\\n\\nPlease provide the full text\\n\\nThis document is a record of a meeting\\n\\n\\nPlease provide the full text!\\n\\n\\nPlease\\n\\n*   Report of a\\n\\n*\\n\\n\\n##.  \\n\\nThe document is a record\\n\\n##  \\n\\nWe need the full text of  \\n\\n## Elections\\n\\nPlease provide the full text\\n\\n## Action Items\\n\\nThe document\\n\\n##  o.  meetings\\n## Events and Announcements\\n\\nThe document is \\n##\\n\\n-  \\n\\n## Contact Information\\n\\n\\nThe document \\n###  \\n\\n* ##  Of  \\n\\n##\\n\\nThe meeting\\n###  \\n\\nWe \\n\\n## Meeting Minutes T\\n\\n\\nPlease provide the full text of the\\n\\n## Summary\\n\\n*  \\n\\nNous avons  \\n\\n***\\n\\n##\\n\\nThe document is a record  \\n\\n##\\n\\n##\\n\\n|\\n\\n##\\n\\n\\nPlease\\n\\n\\n###  \\n\\n##  \\n\\n##  \\n\\n##  \\n\\n\\n\\nPlease provide\\n\\n\\nPlease provide the full text!\\n###  \\n\\n\\nPlease provide \\n\\n\\nPlease provide the official \\n\\nPlease provide the full text. The document appears to be a record of a \\n\\n\\nPlease provide \\nPlease pro\\n###\\n\\nPlease provide\\n_\\n\\nPlease provide \\n\\n\\nPlease\\n\\n##  Please\\n\\n\\nPlease provide the full text!\\nPlease\\n###\\n\\nPlease provide\\n\\n\\nPlease provide\\n\\n##  \\nPlease\\n\\n\\nPlease provide \\n\\n\\nPlease provide\\n\\n###  Minutes\\nPlease\\n\\n\\nPlease\\n\\n##  \\n##########\\nPlease provide\\n\\n\\n###  \\nPlease provide the full text. \\n\\n\\nFinal Text\\nMettre\\n\\n__\\n\\n##  \\n\\n###  \\n\\n\\nPlease provide the full text!\\n\\n____\\n\\n\\n \\n\\n\\nPlease provide the full text\\n\\n\\nPlease provide\\n\\n\\n##  \\n\\n\\nPlease provide \\n\\n##  \\nPlease provide the full text!\\n\\nPlease provide the \\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\n##  \\n\\nPlease provide\\n\\n\\n##\\n\\nPlease provide the full text. \\n\\nPlease provide the\\n##  \\n\\nPlease provide the full textI\\n\\n\\n##  Summary of actions and \\n\\nPlease provide\\n\\n\\nPlease provide\\n\\n__ \\n\\n##\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n##  A decision  \\n\\nPlease \\n\\n\\nPlease provide\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease provide\\n\\nPlease provide the\\n\\n\\nPlease provide\\n\\n\\nPlease\\n\\n\\nPlease provide the full text!\\n \\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n##  \\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide the full text\\n\\n##\\n\\n\\nPlease\\n\\nPlease provide \\n\\n##  \\n\\nPlease provide\\n\\n##\\n\\nPlease provide the full\\n\\n##  Please\\n\\n\\nPlease\\n\\n\\nPlease pro\\n##   Meeting\\n\\n\\nPlease provide the full text.\\n\\nPlease provide\\n\\n## Summary \\n\\n\\nPlease provide the full text.\\n\\nPlease provide the\\n\\n\\nSummary of\\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\n\\nPlease provide\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease provide the full text\\n\\n\\nPlease provide\\n\\n\\nPlease provide\\n\\nPlease provide the\\n\\n##  \\n\\nPlease provide the\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide the\\n\\n\\nPlease provide\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease provide\\n\\n___\\n\\nPlease provide\\n\\n##  \\n\\nPlease provide the full text\\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\nPlease provide\\n\\n##\\n\\nPlease provide the full textI\\n\\n\\nPlease provide\\n\\n##\\n\\nPlease provide\\n\\n\\nPlease provide\\n\\n\\nPlease provide\\n\\n\\nPlease provide the full text!\\n\\nPlease provide \\n\\n\\nPlease provide\\n\\n\\nPlease provide the full text!\\n\\n\\nPlease provide\\n\\n##\\n\\n\\nPlease provide the full text\\n\\nPlease \\n\\nPlease provide the full text\\n\\n\\nPlease\\n\\nPlease provider.\\n\\nPlease provide the full text\\n\\nPlease provide the full text.**Please\\n\\n\\nPlease provide the full text\\n\\n\\nPlease provide\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease provide it\\n\\n\\nPlease provide\\n\\n\\n\\nPlease provide the full text\\n\\nPlease provide the\\n\\nPlease provide the full text. Please pro\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text.\\n\\n##  \\n\\nPlease\\n\\n\\nPlease provide the full text.\\n\\nPlease\\n\\n\\nPlease provide the full text\\n\\nPlease\\n\\n\\nPlease provide th\\n\\n\\nPlease\\n\\nPlease provide the full text\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease provide\\n\\n\\n\\nPlease\\n\\n\\nPlease provide the full text.  Please\\n\\n\\nPlease provide th\\n\\n\\nPlease\\n\\nPlease provide the full text.\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text. Please provide the full\\n\\n\\nPlease provide the full text.Please\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text. Please\\n\\n\\nPlease provide the full text\\n\\n\\n\\n Please\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide th\\n\\n\\nPlease \\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease provide the full text\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the full text.\\n\\nPlease\\n\\nPlease provide the full text.\\n\\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\nPlease provide the full text\\n\\n\\nPlease provide the full text\\n\\nPlease\\n\\n\\nPlease .\\n\\nPlease provide the full text.\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide th\\n\\n\\nPlease provide the full text.\\n\\n\\n\\n **\\n\\n\\nPlease provide the full text\\n\\n\\nPlease provide\\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\n\\nPlease provide the full text\\n\\n\\nPlease pro\\n\\n\\nPlease\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease provide the full text\\n\\n\\nPlease pro\\n\\nPlease Pro\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease pro \\n\\n\\nPlease\\n\\n\\nPlease pro\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease provide the\\n\\nPlease Provide\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\nPlease\\n\\n\\nPlease provide the full text.\\n\\nPlease provide\\n\\n\\n\\n\\nPlease provide the full text.\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide the full text.\\n\\nPlease provide\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease pro\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease provide\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease pro\\n\\nPlease\\n\\n\\n\\n\\nPlease\\n\\n\\nPlease provide the full text.\\n\\n\\n\\n\\nPlease\\nPlease\\n\\n\\nPlease provide the full text.\\n\\nPlease\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease provide the full\\n\\nPlease\\n\\n\\nPlease \\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease provide the full textes\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease provide the full text.\\n\\nPlease \\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease pro\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease Provide\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease \\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease pro\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease \\n\\n\\n\\n\\n\\nWe need\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nP\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n\\n**Please\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\nIndeed, I don\\'\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n \\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n Please\\n\\n**\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\n**Please\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\n\\nPlease\\n\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\n*Please\\n\\n\\nPlease\\n\\n\\nPlease\\n**\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n**\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPleas Please\\n\\n\\n\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\nPlease\\n\\n\\n**\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\nPlease\\n\\n\\nPlease\\n\\n**Please\\n\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\nPlease \\n\\n\\nPlease\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n **Please\\n\\n\\n**\\nPlease\\n\\n\\n**Please\\n\\n**Please\\n\\n\\nPlease\\n\\nPlease\\n\\n\\n\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n **Please\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n**\\n\\n\\nPlease\\n\\n\\n**Please\\n\\nPlease\\n\\n**Please\\n\\n\\nPlease\\n\\n\\n\\n**Please\\n\\n\\nPlease\\n**Please\\n\\n\\n** \\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\nPlease\\n\\n\\n\\n**\\n\\n\\n**\\n\\n\\n\\nPlease\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n**\\n\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n**Please\\n\\n\\n**\\n\\nPlease\\n\\n\\n**Please\\n\\n\\nPlease\\n\\n**Please\\n\\n**\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\nPlease\\n\\n**Please\\n\\n**Please\\n**Please\\n\\n\\n**\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n**Please\\n\\n**Please\\n\\n\\n**\\n\\n\\n**Please\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**\\nPlease\\n\\n\\n**\\n\\nPle\\n**Please\\n\\n\\n\\n**\\n\\nPlease\\n\\n\\n**Please\\n\\n**Please\\n\\n\\n**\\n\\n**\\n\\n******************\\n\\n\\n\\n**\\n\\n\\n**\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n* **Please\\n\\n**\\n\\n\\n**Please\\n\\n\\n\\n**\\n\\n\\n**Please\\n**\\n\\n\\n\\n**\\n\\n\\n\\n**\\n\\n**Please\\n\\n\\n**\\n\\n**\\n\\n\\n\" **Please\\n\\n\\n**\\n\\n**\\n\\n\\n**\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\n\\nPlease\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**\\n\\n\\n**Please\\n\\n**Please\\n\\n\\n***\\n\\n*\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n\" **Please\\n\\n**\\n\\n\\n\\n**\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**\\n\\n\\n\\n\\nPlease\\n\\n\\n**\\n\\n**Please\\n\\n\\n\\n**Please\\n\\n\\n**\\n\\n**\\n\\n**Please\\n\\n\\n\" **Please\\n\\n\\n**Please\\n\\n\\n**\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\n**Please\\n\\n**\\n\\n\\n**Please\\n\\nPlease\\n\\n\\n**Please\\n** *Previous\\n\\n\\n**\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\n**Please\\n\\n**Please\\n\\n\\n\\n**\\n\\n\\n**Please\\n\\n**\\n\\n**Please\\n\\n\\n**\\n\\n\\n\" **Please\\n\\n**\\n\\n\\n\\n**\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n **Please\\n\\n\\n**.\\n\\n**Please\\n\\n**\\n\\n\\n**Please\\n\\n**Please\\n\\n\\n**\\n\\n**Please\\n\\n\\n\\n**Please\\n\\n\\n**\\n\"\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n\\n**Please\\n\\n**Please\\n\\n**Please\\n\\n\\n**Please\\n\\n**\\n\\n**Please')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summ_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_table_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_descriptions_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_tables_chunks[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
