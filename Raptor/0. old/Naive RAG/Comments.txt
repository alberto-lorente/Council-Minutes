Basic current set up:

- DB: chroma
- embeddings: camembert sentence embeddings
- retrieval llm: llama3, the 1 billion parameter version.

Comments:

- indexing new docs may crash your gpu and kernel, do this step in Google Colab and look for a cloud solution.

- the embeddings and indexes are not saved automatically, you have to save them specifically.

- to run models you need to download https://ollama.com/ and the llama3:1b model (more info in the notebook).

