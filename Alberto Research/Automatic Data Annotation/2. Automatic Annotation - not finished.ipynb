{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>url</th>\n",
       "      <th>cache</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>nature</th>\n",
       "      <th>published</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>geo_path</th>\n",
       "      <th>extracted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40369/749929d81bfa6b074fe6844e86b36dec643747bd...</td>\n",
       "      <td>https://sde09.fr/wp-content/uploads/2024/01/Bu...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>comm</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>Syndicat départemental d'énergies de l'Ariège ...</td>\n",
       "      <td>Autre groupement</td>\n",
       "      <td>CC Vendée Grand Littoral/Vendée/Pays de la Loire</td>\n",
       "      <td>BULLETIN D'INFORMATION DU SYNDICAT DÉPARTEMENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2702/19edd8d6b29dcafcb309e0997ddfaef8cca75422_...</td>\n",
       "      <td>https://www.cc-paysdelimours.fr/files/CCPL-202...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>comm</td>\n",
       "      <td>2021-08-22 00:00:00</td>\n",
       "      <td>CC du Pays de Limours (CCPL)</td>\n",
       "      <td>Intercommunalité</td>\n",
       "      <td>CC du Pays de Limours (CCPL)/Essonne/Île-de-Fr...</td>\n",
       "      <td>Communauté de communes du Pays de Limours PCAE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4172/0bf2fa62554e88e675252e51c5720d874aea4c5d_...</td>\n",
       "      <td>https://www.mairie-orly.fr/content/download/16...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>comm</td>\n",
       "      <td>2024-03-21 00:00:00</td>\n",
       "      <td>Orly</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Orly/Métropole du Grand Paris (94)/Val-de-Marn...</td>\n",
       "      <td>AccessDeniedAccess Denied.tx2fe52a9984db4526a1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2774/25ae7_DEL-2022-199_Annexe_Bilan_dactivite...</td>\n",
       "      <td>https://www.grandannecy.fr/fileadmin/mediatheq...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>comm</td>\n",
       "      <td>2022-09-01 00:00:00</td>\n",
       "      <td>CA du Grand Annecy</td>\n",
       "      <td>Intercommunalité</td>\n",
       "      <td>CA du Grand Annecy/Haute-Savoie/Auvergne-Rhône...</td>\n",
       "      <td>H O T E L SOM MAIRE P. 4 administration généra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6472/022f3bc3b0e35408bde88d61f3049899113f21e0_...</td>\n",
       "      <td>https://ville-somain.fr/wp-content/uploads/202...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>https://datapolitics-public.s3.gra.io.cloud.ov...</td>\n",
       "      <td>comm</td>\n",
       "      <td>2021-10-01 00:00:00</td>\n",
       "      <td>Somain</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Somain/CC Cœur d'Ostrevent/Nord/Hauts-de-France</td>\n",
       "      <td>N°42 SEPTEMBRE-OCTOBRE 2020 Création de la bal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              doc_id  \\\n",
       "0  40369/749929d81bfa6b074fe6844e86b36dec643747bd...   \n",
       "1  2702/19edd8d6b29dcafcb309e0997ddfaef8cca75422_...   \n",
       "2  4172/0bf2fa62554e88e675252e51c5720d874aea4c5d_...   \n",
       "3  2774/25ae7_DEL-2022-199_Annexe_Bilan_dactivite...   \n",
       "4  6472/022f3bc3b0e35408bde88d61f3049899113f21e0_...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://sde09.fr/wp-content/uploads/2024/01/Bu...   \n",
       "1  https://www.cc-paysdelimours.fr/files/CCPL-202...   \n",
       "2  https://www.mairie-orly.fr/content/download/16...   \n",
       "3  https://www.grandannecy.fr/fileadmin/mediatheq...   \n",
       "4  https://ville-somain.fr/wp-content/uploads/202...   \n",
       "\n",
       "                                               cache  \\\n",
       "0  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
       "1  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
       "2  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
       "3  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
       "4  https://datapolitics-public.s3.gra.io.cloud.ov...   \n",
       "\n",
       "                                            fulltext nature  \\\n",
       "0  https://datapolitics-public.s3.gra.io.cloud.ov...   comm   \n",
       "1  https://datapolitics-public.s3.gra.io.cloud.ov...   comm   \n",
       "2  https://datapolitics-public.s3.gra.io.cloud.ov...   comm   \n",
       "3  https://datapolitics-public.s3.gra.io.cloud.ov...   comm   \n",
       "4  https://datapolitics-public.s3.gra.io.cloud.ov...   comm   \n",
       "\n",
       "             published                                        entity_name  \\\n",
       "0  2024-01-01 00:00:00  Syndicat départemental d'énergies de l'Ariège ...   \n",
       "1  2021-08-22 00:00:00                       CC du Pays de Limours (CCPL)   \n",
       "2  2024-03-21 00:00:00                                               Orly   \n",
       "3  2022-09-01 00:00:00                                 CA du Grand Annecy   \n",
       "4  2021-10-01 00:00:00                                             Somain   \n",
       "\n",
       "        entity_type                                           geo_path  \\\n",
       "0  Autre groupement   CC Vendée Grand Littoral/Vendée/Pays de la Loire   \n",
       "1  Intercommunalité  CC du Pays de Limours (CCPL)/Essonne/Île-de-Fr...   \n",
       "2           Commune  Orly/Métropole du Grand Paris (94)/Val-de-Marn...   \n",
       "3  Intercommunalité  CA du Grand Annecy/Haute-Savoie/Auvergne-Rhône...   \n",
       "4           Commune    Somain/CC Cœur d'Ostrevent/Nord/Hauts-de-France   \n",
       "\n",
       "                                      extracted_text  \n",
       "0  BULLETIN D'INFORMATION DU SYNDICAT DÉPARTEMENT...  \n",
       "1  Communauté de communes du Pays de Limours PCAE...  \n",
       "2  AccessDeniedAccess Denied.tx2fe52a9984db4526a1...  \n",
       "3  H O T E L SOM MAIRE P. 4 administration généra...  \n",
       "4  N°42 SEPTEMBRE-OCTOBRE 2020 Création de la bal...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"data_experiments.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.grandannecy.fr/fileadmin/mediatheque/Documents_reglementaires/Conseil/2022/09_29/DEL-2022-199_Annexe_Bilan_dactivite_2021_du_Grand_Annecy.pdf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[3][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Data Annotation with Transformers and Mixtral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
    "        HF_TOKEN = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Functions WITH TRANSFORMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: the API only supports a context length of 8k for this model, while the model may support 128k. Some random dude got around the problem by running a private endpoint and changing the 'Container Configuration', specifically the token settings to whatever length they required.\n",
    "\n",
    "Apparent solution PAID: This part is relatively straightforward. Go to the the model card (e.g. https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct), Click on \"Deploy\" in the top right corner and select \"Inference Endpoint\". In the next page you can choose what hardware you want to run the model on, which will impact how much you will pay per hour. Set \"Automatic Scale to Zero\" to some value other than \"never\" to switch off the endpoint after X amount of time without request, so that you won't be paying for the endpoint while it's not in use. Then go to \"Advanced Configuration\" and set the maximum amount of tokens to whatever makes sense for your use case. With this procedure you will be able to make full use of the larger context windows of Llama 3 models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_length_check(text, limit=8000, base_prompt_len=888):# 888 is the length of the current prompt\n",
    "\n",
    "    chars = text.split(\" \")\n",
    "    len_text = len(chars)\n",
    "    if len_text > limit - base_prompt_len: \n",
    "        print(\"Text over max. length. Applying padding.\")\n",
    "        padded_text = \" \".join(chars[:limit - base_prompt_len])\n",
    "        return padded_text \n",
    "    \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(text_to_classify):\n",
    "    base_prompt = f\"\"\"<OBJECTIF_ET_PERSONA>\n",
    "    Vous êtes un annotateur manuel. Votre tâche consiste à dire si un INPUT TEXT concerne un projet ou pas.\n",
    "    </OBJECTIF_ET_PERSONA>\n",
    "\n",
    "    <INSTRUCTIONS>\n",
    "    Suivre ces étapes :\n",
    "    1. Déterminez si le INPUT TEXT concerne un projet ou non.\n",
    "    2. Si le texte concerne un projet, renvoyez 1. Si le INPUT TEXT ne concerne pas un projet, renvoyez 0.\n",
    "    </INSTRUCTIONS>\n",
    "\n",
    "    <FORMAT_DE_SORTIE>\n",
    "    Il doit que votre réponse est un numéro unique: 0 ou 1.\n",
    "    </FORMAT_DE_SORTIE>\n",
    "\n",
    "    <EXEMPLES>\n",
    "    1. INPUT TEXT: \"Pas moins de 200 tableaux peints par les impressionnistes à Bougival ont été répertoriés. Nombreux furent les peintres à s'installer pour un temps à Bougival ou à poser leur chevalet sur les rives de la Seine pour immortaliser paysage et vie en bord du fleuve. Lebourg (Alfred) 1849 – 1928 : attiré par la vallée de la Seine, Albert Lebourg peint à de nombreuses reprises le quai qui borde la Seine venant de Rueil. Il peint Bord de la Seine à Bougival en 1885. Monet (Claude) 1840 – 1926 : il s'installe à Bougival en 1869. Avec son tableau La Seine à Bougival ou le Pont de Bougival peint vers 1869/1870, Claude Monet a représenté l’ancien pont de la ville qui était à péage. Morisot (Berthe) 1841 – 1895 : elle passe plusieurs étés à Bougival de 1881 à 1884 dans la maison qui va devenir, en 2024, l’espace muséal Berthe Morisot. Elle peint à Bougival une quarantaine de toiles : La Fable (1883), Le Quai à Bougival (1883), Eugène Manet et sa fille dans le jardin (1883), Dans la Véranda (1884), Jardin à Bougival (1884), Roses trémières (1884), etc. Pissarro (Camille) 1830 – 1903 : installé à Louveciennes puis à Pontoise, Pissarro peint plusieurs toiles à Bougival : Maisons à Bougival (1870), Bords de la Seine à Bougival (1871), La Route de Louveciennes (1872). Renoir (Auguste) 1849 – 1928 : Renoir n’a jamais séjourné à Bougival, contrairement à son ami Monet, mais\"\n",
    "    0\n",
    "\n",
    "    2. INPUT TEXT: \"AMBITIONS DE LA ZAC : Une réponse aux enjeux contemporains Construit sur une friche industrielle et au contact d’un futur parc et du grand paysage, ce nouveau quartier répond à di\u001férents enjeux : > Sociétaux : • Répondre aux besoins en logements de la commune, • Proposer un quartier avec une densité dé\u001enie pour ralentir l’étalement urbain, • O\u001frir un accès aux services, espaces de santé, commerces et transports en commun, • Desservir le quartier par le réseau de transports en commun de la métropole (prolongation de la ligne 55), • Conserver l’identité culturelle et patrimoniale des lieux grâce au maintien des éléments industriels du site. > Environnementaux : • Renforcer la biodiversité de ce terrain malmené depuis 60 ans, en intégrant des plantations résistantes aux fortes chaleurs et la perméabilisation du site à 50 %. • Dépolluer les sols, • Respecter la charte Écoquartier : obtension de la médaille d’argent QDO en phase conception (Quartier Durable d’Occitanie). • Construire des bâtiments respectant les normes environnementales en vigueur, • Favoriser les modes de transport alternatifs à la voiture : création de pistes cyclables et de cheminements doux, d’une centralité o\u001frant des commerces et des activités, un accès à moins de 10 minutes à pied à la rive droite de la commune, • Préserver la limite entre ville et plaine cultivée. • Protéger les spots de biodiversités identi\u001eés dans l’étude d’impact (environ 7000 m2 ), • O\u001frir un espace public paysager qualitatif avec près d’1 ha de parc urbain et de venelles vertes.\"\n",
    "    1\n",
    "\n",
    "    <INPUT TEXT>\n",
    "    {text_to_classify}\n",
    "    </INPUT TEXT>\n",
    "    \"\"\"\n",
    "    return base_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    messages_tokenized = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    return messages_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_params = dict(\n",
    "    temperature=0.1,\n",
    "    top_p=0.60,\n",
    "    top_k=None,\n",
    "    repetition_penalty=1.0,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=150,\n",
    "    return_full_text=False,\n",
    "    seed=42,\n",
    "    max_time=None,\n",
    "    stream=False,\n",
    "    use_cache=False,\n",
    "    wait_for_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import huggingface_hub\n",
    "\n",
    "def query(payload=None, api_url=None):\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {huggingface_hub.get_token()}\"}\n",
    "api_url = \"https://api-inference.huggingface.co/models/\" + model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_response(response):\n",
    "    \n",
    "#     list_bad_chars = [\"\\\\\", \"\\n\", \"\\t\"]\n",
    "#     for bad_char in list_bad_chars:\n",
    "#         while bad_char in response:\n",
    "#             response = response.replace(bad_char, \"\")\n",
    "    \n",
    "#     # if response.count(\"\\\"\") != 6:\n",
    "#     #     response = response + \"\\\"\"\n",
    "#     if \"}\" not in response:\n",
    "#         response = response + \"}\"\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_response(output):\n",
    "    \n",
    "    regex_expression = r\"[01]\" # try parsing reasons in the future?\n",
    "    regex = re.compile(regex_expression)\n",
    "    match = re.search(regex, output)\n",
    "    # print(match)\n",
    "    parsed_response = match.group()\n",
    "    # print(parsed_response)\n",
    "    return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_annotate(text, verbose=True):\n",
    "    \n",
    "    text = lazy_length_check(text)\n",
    "    \n",
    "    prompt = generate_prompt(text)\n",
    "    prompt_formated = format_prompt(prompt)\n",
    "    \n",
    "    output = query(payload={\"inputs\": prompt_formated, \"parameters\": {**generation_params}}, api_url=api_url)\n",
    "    if verbose:\n",
    "        print(output)\n",
    "    \n",
    "    annotation = parse_response(output[0][\"generated_text\"])\n",
    "    \n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"mistral_annotation\"] = data[\"extracted_text\"].apply(llm_annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = lazy_length_check(example_text)\n",
    "\n",
    "# prompt = generate_prompt(text)\n",
    "# prompt_formated = format_prompt(prompt)\n",
    "\n",
    "# output = query(payload={\"inputs\": prompt_formated, \"parameters\": {**generation_params}}, api_url=api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = output[0][\"generated_text\"]\n",
    "# print(type(response))\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_response = clean_response(response)\n",
    "# new_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_response = parse_response(new_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def llm_correct_json_prompt(json_dict):\n",
    "#     prompt_correct_format =f\"\"\"Vous êtes programmeur. Vous corrigez les erreurs des étudiants lorsqu’ils formatent manuellement les dictionnaires JSON.\n",
    "#     Il s'agit d'un dictionnaire JSON qui n'est pas correctement corrigé:\n",
    "#     {json_dict}\n",
    "#     Renvoie le dictionnaire JSON formaté sur une seule ligne sans erreur.\n",
    "#     <ÉTAPES À SUIVRE>\n",
    "#     1. Vérifiez que toutes les chaînes sont entre guillemets.\n",
    "#     2. Supprimez les retraits, les espaces et les nouvelles lignes.\n",
    "#     3. Vérifiez qu'il y a : après chaque clé et , après les éléments du dictionnaire.\n",
    "#     4. Renvoyez le dictionnaire JSON corrigé. Votre réponse devrait commencer directement.\n",
    "#     5. Vérifiez que la response est 0 ou 1.\"\"\"\n",
    "    \n",
    "#     return prompt_correct_format\n",
    "\n",
    "# def llm_correct_json(prompt_correct_format):\n",
    "    \n",
    "#     prompt_correct_format = llm_correct_json_prompt(prompt_correct_format)\n",
    "#     # print(prompt_correct_format)\n",
    "#     output = query(payload={\"inputs\": prompt_correct_format, \"parameters\": {**generation_params}}, api_url=api_url)\n",
    "    \n",
    "#     return output[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying that we have the correct types to parse\n",
    "# print(type(output_dictionary))\n",
    "# print(type(output_dictionary[\"is_project\"]))\n",
    "# print(type(output_dictionary[\"reason\"]))\n",
    "# print(type(output_dictionary[\"reason\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import NaN\n",
    "\n",
    "# # data[\"mixtral_llm_is_project\"] = NaN\n",
    "# # data[\"mixtral_llm_reasoning\"] = NaN\n",
    "\n",
    "# # how much annotation is left\n",
    "# data[data[\"mixtral_llm_is_project\"].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"data_experiments_annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# index_data_no_annot = list(data[data[\"mixtral_llm_is_project\"].isna()].index)\n",
    "\n",
    "# while len(index_data_no_annot) != 0:\n",
    "    \n",
    "#     print(len(index_data_no_annot), \" left.\")\n",
    "    \n",
    "#     current_index = random.choice(index_data_no_annot)\n",
    "#     print(\"Current index \", current_index)\n",
    "    \n",
    "#     current_text = data.iloc[current_index][\"extracted_text\"]\n",
    "#     print(\"Current text:\", current_text[0:100] + \"...\")\n",
    "    \n",
    "#     output = llm_annotate(current_text)\n",
    "    \n",
    "#     try:\n",
    "        \n",
    "#         response_clean = clean_response(output)\n",
    "#         is_project = parse_response(response_clean)\n",
    "        \n",
    "#         print(\"OUTPUT\\n\")\n",
    "#         print(is_project)\n",
    "#         # print(reasoning)\n",
    "        \n",
    "#         data.at[current_index, \"mixtral_llm_is_project\"] = is_project\n",
    "#         # data.at[current_index, \"mixtral_llm_reasoning\"] = reasoning\n",
    "        \n",
    "#         index_data_no_annot = list(data[data[\"mixtral_llm_is_project\"].isna()].index)\n",
    "        \n",
    "#     except:\n",
    "        \n",
    "#         print(\"Error parsing the LLM output.\\n Calling second agent.\")\n",
    "#         correct_llm_prompt = llm_correct_json_prompt(output)\n",
    "#         output = llm_correct_json(correct_llm_prompt)\n",
    "        \n",
    "#         try:\n",
    "            \n",
    "#             response_clean = clean_response(output)\n",
    "#             is_project = parse_response(response_clean)\n",
    "            \n",
    "#             print(\"OUTPUT\\n\")\n",
    "#             print(is_project)\n",
    "#             # print(reasoning)\n",
    "            \n",
    "#             data.at[current_index, \"mixtral_llm_is_project\"] = is_project\n",
    "#             # data.at[current_index, \"mixtral_llm_reasoning\"] = reasoning\n",
    "            \n",
    "#         except:\n",
    "            \n",
    "#             print(\"Second agent couldn't fix it either.\")\n",
    "#             print(f\"Final output:\\n{output}\")\n",
    "        \n",
    "#         index_data_no_annot = list(data[data[\"mixtral_llm_is_project\"].isna()].index)\n",
    "            \n",
    "#     if current_index % 5 == 0:\n",
    "#         data.to_csv(\"data_experiments_annotated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"data_experiments_annotated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Annotation with Llama3 and LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import NaN\n",
    "\n",
    "data = pd.read_csv(\"data_experiments_annotated.csv\")\n",
    "data[\"llama3:1b_llm_is_project\"] = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_id', 'url', 'cache', 'fulltext', 'nature', 'published',\n",
       "       'entity_name', 'entity_type', 'geo_path', 'extracted_text',\n",
       "       'llama3:1b_llm_is_project'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unannotated_rows = data[data[\"llama3:1b_llm_is_project\"].isna()].shape[0]\n",
    "unannotated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"Vous êtes un annotateur manuel. Votre tâche consiste à dire si un INPUT TEXT concerne un projet ou pas.\n",
    "    Suivre ces étapes:\n",
    "    1. Déterminez si le INPUT TEXT concerne un projet ou non.\n",
    "    2. Si le texte concerne un projet, renvoyez 1. Si le INPUT TEXT ne concerne pas un projet, renvoyez 0.\n",
    "\n",
    "    Il doit que votre réponse est un numéro unique: 0 ou 1.\n",
    "\n",
    "    EXEMPLES\n",
    "    INPUT TEXT: \"Pas moins de 200 tableaux peints par les impressionnistes à Bougival ont été répertoriés. Nombreux furent les peintres à s'installer pour un temps à Bougival ou à poser leur chevalet sur les rives de la Seine pour immortaliser paysage et vie en bord du fleuve. Lebourg (Alfred) 1849 – 1928 : attiré par la vallée de la Seine, Albert Lebourg peint à de nombreuses reprises le quai qui borde la Seine venant de Rueil. Il peint Bord de la Seine à Bougival en 1885. Monet (Claude) 1840 – 1926 : il s'installe à Bougival en 1869. Avec son tableau La Seine à Bougival ou le Pont de Bougival peint vers 1869/1870, Claude Monet a représenté l’ancien pont de la ville qui était à péage. Morisot (Berthe) 1841 – 1895 : elle passe plusieurs étés à Bougival de 1881 à 1884 dans la maison qui va devenir, en 2024, l’espace muséal Berthe Morisot. Elle peint à Bougival une quarantaine de toiles : La Fable (1883), Le Quai à Bougival (1883), Eugène Manet et sa fille dans le jardin (1883), Dans la Véranda (1884), Jardin à Bougival (1884), Roses trémières (1884), etc. Pissarro (Camille) 1830 – 1903 : installé à Louveciennes puis à Pontoise, Pissarro peint plusieurs toiles à Bougival : Maisons à Bougival (1870), Bords de la Seine à Bougival (1871), La Route de Louveciennes (1872). Renoir (Auguste) 1849 – 1928 : Renoir n’a jamais séjourné à Bougival, contrairement à son ami Monet, mais\"\n",
    "    OUTPUT: 0\n",
    "\n",
    "    INPUT TEXT: \"AMBITIONS DE LA ZAC : Une réponse aux enjeux contemporains Construit sur une friche industrielle et au contact d’un futur parc et du grand paysage, ce nouveau quartier répond à di\u001férents enjeux : > Sociétaux : • Répondre aux besoins en logements de la commune, • Proposer un quartier avec une densité dé\u001enie pour ralentir l’étalement urbain, • O\u001frir un accès aux services, espaces de santé, commerces et transports en commun, • Desservir le quartier par le réseau de transports en commun de la métropole (prolongation de la ligne 55), • Conserver l’identité culturelle et patrimoniale des lieux grâce au maintien des éléments industriels du site. > Environnementaux : • Renforcer la biodiversité de ce terrain malmené depuis 60 ans, en intégrant des plantations résistantes aux fortes chaleurs et la perméabilisation du site à 50 %. • Dépolluer les sols, • Respecter la charte Écoquartier : obtension de la médaille d’argent QDO en phase conception (Quartier Durable d’Occitanie). • Construire des bâtiments respectant les normes environnementales en vigueur, • Favoriser les modes de transport alternatifs à la voiture : création de pistes cyclables et de cheminements doux, d’une centralité o\u001frant des commerces et des activités, un accès à moins de 10 minutes à pied à la rive droite de la commune, • Préserver la limite entre ville et plaine cultivée. • Protéger les spots de biodiversités identi\u001eés dans l’étude d’impact (environ 7000 m2 ), • O\u001frir un espace public paysager qualitatif avec près d’1 ha de parc urbain et de venelles vertes.\"\n",
    "    OUTPUT: 1\n",
    "\n",
    "    Déterminer quel devrait être le output de ce texte:\n",
    "    {text_to_classify}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt_2 =\"\"\"CE DOCUMENT PARLE-T-IL D'UN PROJET ? RÉPONDRE OUI OU NON. LE FORMAT FINAL DEVRAIT ÊTRE UN DICTIONNAIRE JSON.\n",
    "INPUT TEXT:{text_to_classify}\n",
    "VOTRE OUTPUT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Mission Chaleur Renouvelable (MCR) est un service proposé par l'Agence NOVA pour accompagner les habitants des communautés ariégiennes dans la rénovation énergétique. Voici quelques informations clés sur ce service :\n",
      "\n",
      "**Objectif**\n",
      "\n",
      "La mission vise à aider les maitres d'ouvrages àriégeois (qui possèdent un numéro SIRET) à réussir leur projet de rénovation énergétique en leur offrant des conseils techniques et financiers.\n",
      "\n",
      "**Projets qui peuvent bénéficier du service**\n",
      "\n",
      "Les projets qui font appel à des systèmes, chaufferies automatiques dédiées ou réseaux de production de chaleur (ou froid) à partir des énergies renouvelables thermiques sont admis. Ces projets peuvent être de type :\n",
      "\n",
      "* Chauffage centralisé\n",
      "* Chauvesource\n",
      "* Réseaux de chauffe\n",
      "\n",
      "**Avantages du service**\n",
      "\n",
      "La Mission Chaleur Renouvelable offre plusieurs avantages aux maitres d'ouvrages, notamment :\n",
      "\n",
      "* Des conseils techniques objectifs et gratuits pour définir le système adapté et optimiser les installations en fonctionnement\n",
      "* Un suivi des installations pour garantir un montage réussi\n",
      "* Une structuration et suivi de la filière d'approvisionnement bois énergie\n",
      "* Des subventions pour les projets qui font appel à des systèmes, chaufferies automatiques dédiées ou réseaux de production de chaleur (ou froid) à partir des énergies renouvelables thermiques\n",
      "\n",
      "**Règles et conditions**\n",
      "\n",
      "Pour passer aux énergies renouvelables thermiques :\n",
      "\n",
      "* Vous devez répondre à la réglementation (RE2020, Décret Tertiaire...)\n",
      "* Vous devez vous chercher des solutions de rénovation énergétique\n",
      "* Les subventions sont dégagées sur des dépenses éligibles (suivant les conditions d'éligibilité)\n",
      "\n",
      "**Formules de paiement**\n",
      "\n",
      "La Mission Chaleur Renouvelable propose plusieurs formules de paiement, notamment :\n",
      "\n",
      "* 45% des dépenses éligibles pour les maitres d'ouvrages ariégeois\n",
      "* 80% des dépenses éligibles pour les autres groupes cibles\n",
      "\n",
      "**Conseils et informations**\n",
      "\n",
      "La mission MCR offre également des animations pour mieux comprendre les avantages et les limites de la Mission Chaleur Renouvelable. Vous pouvez également contacter l'Agence NOVA pour obtenir plus d'informations sur le service.\n",
      "\n",
      "En résumé, la Mission Chaleur Renouvelable est un service proposé par l'Agence NOVA pour aider les maitres d'ouvrages àriégeois à réussir leur projet de rénovation énergétique en leur offrant des conseils techniques et financiers.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\") # 128k token window size\n",
    "\n",
    "def llm_annotate_langchain(text_to_classify, base_prompt=base_prompt):\n",
    "    \n",
    "    prompt_template = PromptTemplate(input_variables=[\"text_to_classify\"],\n",
    "                                    template=base_prompt)\n",
    "    prompt = prompt_template.format(text_to_classify = text_to_classify)\n",
    "    output = llm.invoke(prompt)\n",
    "    annotation = parse_response(output)\n",
    "    \n",
    "    return annotation, output\n",
    "\n",
    "example = data.iloc[0][\"extracted_text\"]\n",
    "annotation, output = llm_annotate_langchain(example, base_prompt)\n",
    "print(annotation)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"llama3:1b_llm_is_project\"] = data[\"extracted_text\"].apply(llm_annotate_langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"data_experiments_annotated.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
