{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_md_to_text.txt\", \"r\", encoding=\"latin-1\") as f: # TO DO: check proper encoding for .md files\n",
    "    markdown_example = f.read()\n",
    "\n",
    "with open(\"example.pdf\", \"rb\") as f:\n",
    "    pdf = f.read()\n",
    "\n",
    "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
    "    hf_token = f.read()\n",
    "\n",
    "with open(\"GROQ_KEY.txt\", \"r\") as f:\n",
    "    groq_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alberto-lorente\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder, whoami\n",
    "\n",
    "HfFolder.save_token(hf_token)\n",
    "print(whoami()[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda available\")\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"example.pdf\"\n",
    "\n",
    "base_prompt=\"\"\"CONTEXTE\n",
    "L'image suivante contient une page et un tableau. \n",
    "\n",
    "TÂCHE\n",
    "Décrivez le tableau et le contenu de la page en accordant une attention particulière au contexte qui l'entoure, qu'il s'agisse de budgets, de dates, d'élections, d'agendas, de projets futurs ou de sujets connexes. \n",
    "\n",
    "FORMAT DE LA RÉPONSE\n",
    "Votre réponse doit être aussi détaillée que possible. \n",
    "Votre résultat doit être la description du tableau directement.\n",
    "La langue de votre réponse est le français\"\"\"\n",
    "\n",
    "\n",
    "summary_prompt = \"\"\"Il s'agit d'un texte concernant un projet de géothermie :\n",
    "TEXTE: \n",
    "{}\n",
    "\n",
    "TÂCHE:\n",
    "Make a one page summary paying special attention to all the administrative matters like budgets, plans, actions to take in the future, organizational and hierarchical charts, announcements, meetings, contacts, elections, reports and all the related topics to these.\n",
    "\n",
    "OUTPUT:\n",
    "Publier directement le résumé.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def unload_cuda():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "unload_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from council_rag.preprocessing import preprocess_markdown_text\n",
    "from council_rag.data_transformations import process_tables, summarize_clusters\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "paragraphs_list, clusters_dict, model = preprocess_markdown_text(markdown_example,\n",
    "                                                        model_id =\"Jaume/gemma-2b-embeddings\", \n",
    "                                                        spacy_model=\"fr_core_news_sm\", \n",
    "                                                        n_sents_per_para=8,\n",
    "                                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unload_cuda()\n",
    "processed_tables = process_tables(pdf_path, \n",
    "                                base_prompt, \n",
    "                                groq_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cluster_0', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6', 'cluster_7'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.375812216599781\n"
     ]
    }
   ],
   "source": [
    "unload_cuda()\n",
    "clusters_dict = summarize_clusters(clusters_dict, \n",
    "                                    summary_prompt, \n",
    "                                    groq_token, \n",
    "                                    model=\"gemma2-9b-it\", \n",
    "                                    token_limit=14000, \n",
    "                                    sleep_time=60)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we are going to query are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraphs_dict \n",
    "# processed_tables\n",
    "# clusters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting some info that we won't need and turning the cluster dict into a list to match the paragraphs list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del paragraphs_list[0][\"para_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_list = list(clusters_dict.values())\n",
    "i = 0\n",
    "while i < len(clusters_list):\n",
    "    clusters_list[i][\"cluster\"] = i\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the embedding model and setting up the index and vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the embedding to pass it to the index\n",
    "shape_emb = embedding_model.encode(\"Hello World!\")\n",
    "emd_dims =  shape_emb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# init the intex\n",
    "index = faiss.IndexFlatL2(emd_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# creating the vector store\n",
    "vector_store = FAISS(embedding_model, \n",
    "                    index, \n",
    "                    InMemoryDocstore({}), \n",
    "                    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['para_indexes', 'union_paras', 'cluster_summary', 'cluster'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_list[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing all the information we have collected so far into Document objects that will be fed into the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paras = [] # to process into smaller chunks\n",
    "cluster_summ_docs = [] # filled with the cluster summaries langchain doc type\n",
    "\n",
    "for cluster in clusters_list:\n",
    "    \n",
    "    cluster_para = cluster[\"union_paras\"]\n",
    "    cluster_summ = cluster[\"cluster_summary\"]\n",
    "    \n",
    "    cluster_paras.append(cluster_para)\n",
    "    cluster_summ_docs.append(Document(page_content=cluster_summ, metadata={\"cluster\": cluster[\"cluster\"],\n",
    "                                                                            \"type\": \"summary\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=450, \n",
    "                                        chunk_overlap=35,\n",
    "                                        length_function=len,\n",
    "                                        is_separator_regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paras_docs = []\n",
    "for cluster_union in cluster_paras:\n",
    "    cluster_union_docs = splitter.split_text(cluster_union)\n",
    "    cluster_paras_docs.append(cluster_union_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_paras_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_chunks = []\n",
    "i = 0\n",
    "while i < len(cluster_paras_docs):  \n",
    "    curr_cluster = cluster_paras_docs[i]\n",
    "    for cluster_chunk in curr_cluster:\n",
    "        cluster_chunks.append(Document(page_content=cluster_chunk, metadata={\"cluster\": i,\n",
    "                                                                                \"type\": \"cluster_chunk\"}))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_table_chunks = []\n",
    "table_descriptions_chunks = []\n",
    "html_tables_chunks = []\n",
    "\n",
    "for table in processed_tables:\n",
    "    augmented_chunk = table[\"table_augmented_context\"]\n",
    "    augmented_table_chunks.append(Document(page_content=augmented_chunk, metadata={\"type\": \"augmented_table\"}))\n",
    "    \n",
    "    description_chunk = table[\"table_context\"]\n",
    "    table_descriptions_chunks.append(Document(page_content=description_chunk, metadata={\"type\": \"description_table\"}))\n",
    "    \n",
    "    html_chunk = table[\"table_html\"]\n",
    "    html_tables_chunks.append(Document(page_content=html_chunk, metadata={\"type\": \"html_table\"}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we have:\n",
    "\n",
    "- The individual text chunks.\n",
    "- The clusters summaries chunks.\n",
    "- The augmented table chunks.\n",
    "- The table descriptions chunks.\n",
    "- The html tables chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'cluster': 0, 'type': 'cluster_chunk'}, page_content=\"Rue des Vernes à Roanne\\n\\n\\n\\n # PROCES VERBAL\\n\\n\\n\\n L'an deux mille vingt et un, le 28 octobre à 18 h 00, les conseillers communautaires de Roannais Agglomération, se sont réunis à l\\x92Espace Chorum \\x96 Halle Vacheresse \\x96 Rue des Vernes à Roanne.\\n\\n\\n\\nLa convocation de tous les conseillers a été faite le 22 octobre 2021, dans les formes et délais prescrits par la loi, par Yves Nicolin, Président.\\n\\n\\n\\n # Etaient présents :\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'cluster': 0, 'type': 'summary'}, page_content='## Résumé du Procès-Verbal des Conseillers Communautaires de Roannais Agglomération \\n\\n**Date:** 28 octobre 2021\\n\\n**Lieu:** Espace Chorum - Halle Vacheresse - Rue des Vernes à Roanne\\n\\n**Présidence:** Yves Nicolin\\n\\nCe procès-verbal résume les décisions prises lors de la réunion du conseil communal de Roannais Agglomération le 28 octobre 2021. \\n\\n**Permissions et Conventions:**\\n\\n* **Droit de chasse:** La Fédération Départementale des Chasseurs de la Loire a obtenu un droit de chasse pédagogique sur le site Domaine des Grands Murcins. Ce droit est limité au grand gibier et aux espèces nuisibles, sans agrainage.\\n* **Construction Bâtiment d\\'Enseignement Supérieur:** Un avenant au contrat du lot 10  \"Serrurerie\" concernant les travaux de construction d\\'un Bâtiment d\\'Enseignement Supérieur sur le Campus Mendes France à Roanne (phase 2) a été approuvé avec la société ROCHE.\\n* **Avenant Spectacle \"BoOm\":**  L\\'avenant au contrat de cession du spectacle \"BoOm\" avec la compagnie \"Entre Eux Deux Rives\" a été approuvé.\\n\\n**Occupations de bâtiments:**\\n\\n*  La société SUPERBE AILE FORMATION obtient l\\'occupation du bâtiment \"Fox - Trot\" situé sur le site aéroportuaire de Roanne-Bois de Pouilly.\\n\\n\\n**Subventions:**\\n\\n*  Une subvention de 5 500 € est attribuée à l\\'association \"Vignobles Forez Roannais, Aux Racines de la Loire\" pour le territoire du vignoble Roannais.\\n\\n**Conventions de prestation de services:** \\n\\n*  L\\'avenant n°1 aux conventions de prestation de services avec les communes d\\'Ambierle, Mably, OPHEOR, Ouches, Pouilly-les-Nonains, Roannaise de l\\'Eau, Renaison, Riorges, Saint-Martin-d\\'Estreaux, Saint-Romain-la-Motte, Saint-Alban-les-Eaux, Saint-André-d\\'Apchon et Villerest a été approuvé. Ces conventions prennent fin le 31 décembre 2021.\\n\\n**(Important à noter que le procès-verbal ne fournit pas d\\'informations sur les plans d\\'aménagement, les budgets détaillés, les organisations internes, les prochains défis, les rapports financiers, les contacts spécifiques ou les résultats des élections.)**\\n\\n\\n\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summ_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'type': 'augmented_table'}, page_content='Cette page et le tableau sont l\\'univers de la contestation politique issue du mouvement municipaliste breton. Il est à noter que l\\'ensemble des informations, lorsqu\\'il les connaissait, ou les prenait pour réelle, se révèle être erroné ou faux.\\n\\nLa suite de la réponse se trouve dans l\\'encadré \"SITUATION DE LA PAGE\".\\n    \\nTableau au format html:\\n\\n<table>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Absents\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Ni pouvoir\\n   <br/>\\n   Ni suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Pouvoir donné à…\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Marc Ambroise\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Laurence Boyer\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-France Catheland\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Muriel Marcellin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Chambost\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Clotilde Robin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Aimé Combaret\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Laure Dana Burnichon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Edmond Bourgeon\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   -\\n   <br/>\\n   Jean-Marc Detour\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Catherine Brun\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Daniel Fréchet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Lucien Murzi\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Quentin Guillermin\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Paul Heyberger\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christelle Lattat\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Franck Maupetit\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Annie Gerenton\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Patrick Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Nabih Nejjar\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Gilles Passot\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Fabien Lambert\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marcel Peuillon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Didier Prunet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christian Dupuis\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Vickie Redeuilh\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Hélène Lapalus\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Hélène Riamon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Denis Vanhecke\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Corinne Troncy\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Maryvonne Loughraieb\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Isabelle Valcourt\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Luc Mardeuil\\n  </td>\\n </tr>\\n</table>')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_table_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'type': 'description_table'}, page_content='Cette page et le tableau sont l\\'univers de la contestation politique issue du mouvement municipaliste breton. Il est à noter que l\\'ensemble des informations, lorsqu\\'il les connaissait, ou les prenait pour réelle, se révèle être erroné ou faux.\\n\\nLa suite de la réponse se trouve dans l\\'encadré \"SITUATION DE LA PAGE\".')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_descriptions_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'type': 'html_table'}, page_content='Cette page et le tableau sont l\\'univers de la contestation politique issue du mouvement municipaliste breton. Il est à noter que l\\'ensemble des informations, lorsqu\\'il les connaissait, ou les prenait pour réelle, se révèle être erroné ou faux.\\n\\nLa suite de la réponse se trouve dans l\\'encadré \"SITUATION DE LA PAGE\".\\n    \\nTableau au format html:\\n\\n<table>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Absents\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Ni pouvoir\\n   <br/>\\n   Ni suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Pouvoir donné à…\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Marc Ambroise\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Laurence Boyer\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-France Catheland\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Muriel Marcellin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Chambost\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Clotilde Robin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Aimé Combaret\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Laure Dana Burnichon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Edmond Bourgeon\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   -\\n   <br/>\\n   Jean-Marc Detour\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Catherine Brun\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Daniel Fréchet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Lucien Murzi\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Quentin Guillermin\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Paul Heyberger\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christelle Lattat\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Franck Maupetit\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Annie Gerenton\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Patrick Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Nabih Nejjar\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Gilles Passot\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Fabien Lambert\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marcel Peuillon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Didier Prunet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christian Dupuis\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Vickie Redeuilh\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Hélène Lapalus\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Hélène Riamon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Denis Vanhecke\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Corinne Troncy\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Maryvonne Loughraieb\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Isabelle Valcourt\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Luc Mardeuil\\n  </td>\\n </tr>\\n</table>')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tables_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = cluster_chunks + cluster_summ_docs + augmented_table_chunks + table_descriptions_chunks + html_tables_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [i for i in range(len(all_docs))]\n",
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking types of the docs\n",
    "# for doc in all_docs:\n",
    "#     print(type(doc))\n",
    "#     print(doc.metadata)\n",
    "#     print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(vector_store.add_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rue des Vernes à Roanne\\n\\n\\n\\n # PROCES VERBAL\\n\\n\\n\\n L'an deux mille vingt et un, le 28 octobre à 18 h 00, les conseillers communautaires de Roannais Agglomération, se sont réunis à l\\x92Espace Chorum \\x96 Halle Vacheresse \\x96 Rue des Vernes à Roanne.\\n\\n\\n\\nLa convocation de tous les conseillers a été faite le 22 octobre 2021, dans les formes et délais prescrits par la loi, par Yves Nicolin, Président.\\n\\n\\n\\n # Etaient présents :\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council_rag.preprocessing.preprocessing import compute_norm_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = [compute_norm_embeddings(embedding_model, doc.page_content) for doc in all_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# adding the documents to the vectorstore\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# if this still does not work, we can do FAISS.from_texts with the embeddings computed manually\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:286\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    285\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m )\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:340\u001b[0m, in \u001b[0;36mFAISS.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run more texts through the embeddings and add to the vectorstore.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m--> 340\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add(texts, embeddings, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:250\u001b[0m, in \u001b[0;36mFAISS._embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[0;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:438\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m     trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    437\u001b[0m         key: value\n\u001b[1;32m--> 438\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    440\u001b[0m     }\n\u001b[0;32m    442\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    443\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# adding the documents to the vectorstore\n",
    "\n",
    "vector_store.add_documents(documents=cluster_chunks, ids=ids)\n",
    "# if this still does not work, we can do FAISS.from_texts with the embeddings computed manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UP UNTIL THIS POINT, EVERYTHING IS PACKAGED MISSING THE ACTUAL POPULATING OF THE DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Get from Tunji's thingie\"\n",
    "\n",
    "results = vector_store.similarity_search(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"}, # put the clustering, etc here\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\") # this is how to get the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK WITH THE FIXED VECTOR STORE BEFORE PACKAGING INTO COUNCIL_RAG.RAG AND MAIN.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo to query the store in the right order\n",
    "def query_vector_store(vector_store, query):\n",
    "        # first search through the summaries\n",
    "        results_query_level_one = vector_store.similarity_search(\n",
    "                                                                query,\n",
    "                                                                k=1,\n",
    "                                                                filter={\"type\": \"summary\"}, \n",
    "                                                                )\n",
    "\n",
    "        cluster_level_one = results_query_level_one[0].metadata[\"cluster\"]\n",
    "\n",
    "        # now we search only in the cluster retrieved in the first step\n",
    "        results_query_level_two = vector_store.similarity_search(\n",
    "                                                        query,\n",
    "                                                        k=5,\n",
    "                                                        filter={\"cluster\": cluster_level_one,\n",
    "                                                                \"type\": \"cluster_chunk\"}, \n",
    "                                                        )\n",
    "        results_query_tables = vector_store.similarity_search(\n",
    "                                                        query,\n",
    "                                                        k=1,\n",
    "                                                        filter={\"type\": 'description_table'}, # {\"$in\": []} \n",
    "                                                        )\n",
    "        \n",
    "        relevant_facts = [sent_query_level_two.page_content for sent_query_level_two in results_query_level_two]\n",
    "        relevant_table = results_query_tables.page_content\n",
    "        \n",
    "        return relevant_facts, relevant_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_query_rag(query, relevant_facts, relevant_table):\n",
    "    \n",
    "    aug_prompt=\"\"\"\\nVoici quelques faits pertinents pour vous aider à répondre et una description du qui peut s'avérer utile. \n",
    "    Si la description du n'est pas utile, ignorez-le.\\n\"\"\"\n",
    "    \n",
    "    augmented_data_string = aug_prompt + \"\\n\".join(relevant_facts) + \"\\n\" + relevant_table\n",
    "    \n",
    "    formated_augmented_query = query.format(augmented_data_string) # the original query has to have a format string\n",
    "    # formated_augmented_query = query + augmented_data_string       # if that is not the case, we can do this instead\n",
    "    \n",
    "    return formated_augmented_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def final_query(query, model, groq_key):\n",
    "    \n",
    "    client = Groq(api_key=groq_key)\n",
    "    \n",
    "    messages = [\n",
    "                {\"role\": \"system\",\n",
    "                \"content\":  \"Vous êtes un assistant utile\" },\n",
    "                {\"role\": \"user\",\n",
    "                \"content\":  query}\n",
    "                ]\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(messages=messages, model=model)\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final fx to query our list of queries\n",
    "\n",
    "def query_multiple(list_of_queries, vector_store, model, groq_key):\n",
    "    \n",
    "    responses = []\n",
    "    for query in list_of_queries:\n",
    "        \n",
    "        relevant_facts, relevant_table = query_vector_store(vector_store, query)\n",
    "        formated_augmented_query = augment_query_rag(query, relevant_facts, relevant_table)\n",
    "        response = final_query(formated_augmented_query, model, groq_key)\n",
    "        responses.append(response)\n",
    "    \n",
    "    return responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
