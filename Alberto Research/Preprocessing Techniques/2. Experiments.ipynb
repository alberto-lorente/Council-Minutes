{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxcHZC7EaxIO"
      },
      "source": [
        "REQUIREMENTS.TXT\n",
        "EXAMPLE_MD_TO_TEXT.TXT\n",
        "HF_TOKEN.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P_9551bjnMHb"
      },
      "outputs": [],
      "source": [
        "with open(\"example_md_to_text.txt\", \"r\", encoding=\"latin-1\") as f: # TO DO: check proper encoding for .md files\n",
        "    markdown_example = f.read()\n",
        "\n",
        "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
        "    hf_token = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzh65usQ4gyd",
        "outputId": "63190ba4-1ba1-410f-c2a1-45e07d2b1b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aiohappyeyeballs==2.4.4 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiohttp==3.11.11 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 2)) (3.11.11)\n",
            "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: anyio==4.8.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: asttokens==3.0.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: attrs==24.3.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 7)) (24.3.0)\n",
            "Requirement already satisfied: certifi==2024.12.14 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 8)) (2024.12.14)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 9)) (3.4.1)\n",
            "Requirement already satisfied: colorama==0.4.6 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 10)) (0.4.6)\n",
            "Requirement already satisfied: comm==0.2.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 11)) (0.2.2)\n",
            "Requirement already satisfied: datasets==3.2.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: debugpy==1.8.12 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 13)) (1.8.12)\n",
            "Requirement already satisfied: decorator==5.1.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 14)) (5.1.1)\n",
            "Requirement already satisfied: dill==0.3.8 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 15)) (0.3.8)\n",
            "Requirement already satisfied: executing==2.1.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 16)) (2.1.0)\n",
            "Requirement already satisfied: filelock==3.16.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 17)) (3.16.1)\n",
            "Requirement already satisfied: frozenlist==1.5.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 18)) (1.5.0)\n",
            "Requirement already satisfied: fsspec==2024.9.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 19)) (2024.9.0)\n",
            "Requirement already satisfied: h11==0.14.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 20)) (0.14.0)\n",
            "Requirement already satisfied: httpcore==1.0.7 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 21)) (1.0.7)\n",
            "Requirement already satisfied: httpx==0.27.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 22)) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub==0.27.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 23)) (0.27.1)\n",
            "Requirement already satisfied: idna==3.10 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 24)) (3.10)\n",
            "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 25)) (6.29.5)\n",
            "Requirement already satisfied: ipython==8.31.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 26)) (8.31.0)\n",
            "Requirement already satisfied: jedi==0.19.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 27)) (0.19.2)\n",
            "Requirement already satisfied: Jinja2==3.1.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 28)) (3.1.3)\n",
            "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 29)) (8.6.3)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 30)) (5.7.2)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 31)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 32)) (0.1.7)\n",
            "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 33)) (1.3.0)\n",
            "Requirement already satisfied: multidict==6.1.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 34)) (6.1.0)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 35)) (0.70.16)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 36)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 37)) (3.2.1)\n",
            "Requirement already satisfied: numpy==2.2.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 38)) (2.2.1)\n",
            "Requirement already satisfied: ollama==0.4.6 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 39)) (0.4.6)\n",
            "Requirement already satisfied: packaging==24.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 40)) (24.2)\n",
            "Requirement already satisfied: pandas==2.2.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 41)) (2.2.3)\n",
            "Requirement already satisfied: parso==0.8.4 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 42)) (0.8.4)\n",
            "Requirement already satisfied: platformdirs==4.3.6 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 43)) (4.3.6)\n",
            "Requirement already satisfied: prompt_toolkit==3.0.49 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 44)) (3.0.49)\n",
            "Requirement already satisfied: propcache==0.2.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 45)) (0.2.1)\n",
            "Requirement already satisfied: psutil==6.1.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 46)) (6.1.1)\n",
            "Requirement already satisfied: pure_eval==0.2.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 47)) (0.2.3)\n",
            "Requirement already satisfied: pyarrow==18.1.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 48)) (18.1.0)\n",
            "Requirement already satisfied: pydantic==2.10.5 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 49)) (2.10.5)\n",
            "Requirement already satisfied: pydantic_core==2.27.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 50)) (2.27.2)\n",
            "Requirement already satisfied: Pygments==2.19.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 51)) (2.19.1)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 52)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz==2024.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 53)) (2024.2)\n",
            "Requirement already satisfied: pywin32==308 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 54)) (308)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 55)) (6.0.2)\n",
            "Requirement already satisfied: pyzmq==26.2.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 56)) (26.2.0)\n",
            "Requirement already satisfied: regex==2024.11.6 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 57)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 58)) (2.32.3)\n",
            "Requirement already satisfied: safetensors==0.5.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 59)) (0.5.2)\n",
            "Requirement already satisfied: setuptools==70.0.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 60)) (70.0.0)\n",
            "Requirement already satisfied: six==1.17.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 61)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 62)) (1.3.1)\n",
            "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 63)) (0.6.3)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 64)) (1.13.1)\n",
            "Requirement already satisfied: tokenizers==0.21.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 65)) (0.21.0)\n",
            "Requirement already satisfied: torch==2.5.1+cu118 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 66)) (2.5.1+cu118)\n",
            "Requirement already satisfied: tornado==6.4.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 67)) (6.4.2)\n",
            "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 68)) (4.67.1)\n",
            "Requirement already satisfied: traitlets==5.14.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 69)) (5.14.3)\n",
            "Collecting transformers==4.48.0 (from -r requirements.txt (line 70))\n",
            "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: typing_extensions==4.12.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 71)) (4.12.2)\n",
            "Requirement already satisfied: tzdata==2024.2 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 72)) (2024.2)\n",
            "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 73)) (2.3.0)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 74)) (0.2.13)\n",
            "Requirement already satisfied: xxhash==3.5.0 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 75)) (3.5.0)\n",
            "Requirement already satisfied: yarl==1.18.3 in c:\\users\\alber\\desktop\\envs\\.council-rag\\.council-rag\\lib\\site-packages (from -r requirements.txt (line 76)) (1.18.3)\n",
            "Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
            "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.5/9.7 MB 3.4 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 1.0/9.7 MB 2.8 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 2.1/9.7 MB 3.8 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 3.9/9.7 MB 5.1 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 5.8/9.7 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 6.8/9.7 MB 5.7 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 7.9/9.7 MB 5.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.9/9.7 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.7/9.7 MB 5.5 MB/s eta 0:00:00\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.1\n",
            "    Uninstalling transformers-4.48.1:\n",
            "      Successfully uninstalled transformers-4.48.1\n",
            "Successfully installed transformers-4.48.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdlNS5bAENlC",
        "outputId": "40402f3a-b4f1-4ac4-bdc7-ce1fb92b5a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr-core-news-sm==3.8.0"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.3/16.3 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.5/16.3 MB 1.7 MB/s eta 0:00:10\n",
            "     - -------------------------------------- 0.8/16.3 MB 1.6 MB/s eta 0:00:10\n",
            "     --- ------------------------------------ 1.3/16.3 MB 1.4 MB/s eta 0:00:11\n",
            "     --- ------------------------------------ 1.6/16.3 MB 1.4 MB/s eta 0:00:11\n",
            "     ---- ----------------------------------- 1.8/16.3 MB 1.5 MB/s eta 0:00:10\n",
            "     ----- ---------------------------------- 2.4/16.3 MB 1.6 MB/s eta 0:00:09\n",
            "     ------- -------------------------------- 2.9/16.3 MB 1.7 MB/s eta 0:00:08\n",
            "     -------- ------------------------------- 3.4/16.3 MB 1.8 MB/s eta 0:00:08\n",
            "     --------- ------------------------------ 3.9/16.3 MB 1.9 MB/s eta 0:00:07\n",
            "     ---------- ----------------------------- 4.5/16.3 MB 2.0 MB/s eta 0:00:06\n",
            "     ------------ --------------------------- 5.2/16.3 MB 2.1 MB/s eta 0:00:06\n",
            "     -------------- ------------------------- 5.8/16.3 MB 2.2 MB/s eta 0:00:05\n",
            "     ---------------- ----------------------- 6.6/16.3 MB 2.3 MB/s eta 0:00:05\n",
            "     ----------------- ---------------------- 7.1/16.3 MB 2.3 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 8.1/16.3 MB 2.4 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 8.9/16.3 MB 2.6 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 10.0/16.3 MB 2.7 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 11.0/16.3 MB 2.8 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.5/16.3 MB 2.8 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.5/16.3 MB 2.8 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.5/16.3 MB 2.8 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 12.1/16.3 MB 2.5 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 13.4/16.3 MB 2.7 MB/s eta 0:00:02\n",
            "     ------------------------------------- -- 15.2/16.3 MB 3.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 16.3/16.3 MB 3.1 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gr2NScMJ4gye"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import tqdm\n",
        "# pprint(markdown_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMquaPnI4gye"
      },
      "source": [
        "Basic OLlama Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rmAT1Yjs4gye"
      },
      "outputs": [],
      "source": [
        "# import ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B0fIFS9d4gyf"
      },
      "outputs": [],
      "source": [
        "# # basic workflow of getting llama embeddings with ollama\n",
        "# ollama.embeddings(model=\"llama3.2:3b\",\n",
        "#                 prompt=\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BV0isCso4gyf"
      },
      "outputs": [],
      "source": [
        "# # basic workflow of generating responses with ollama\n",
        "# ollama.generate(model=\"llama3.2:3b\",\n",
        "#                 prompt=\"Whos is Obama\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ImuB4zw4gyf"
      },
      "source": [
        "Loading HF to get Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CETuQGDb4gyf"
      },
      "outputs": [],
      "source": [
        "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
        "    hf_token = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsbEhjmB4gyf",
        "outputId": "d6885c31-80b1-412f-a60f-349a0d3fdf30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alberto-lorente\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import HfFolder, whoami\n",
        "\n",
        "HfFolder.save_token(hf_token)\n",
        "print(whoami()[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFFEdmNL4gyg",
        "outputId": "ece889cd-e17a-452c-c64e-ae09a21b0532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda available\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda available\")\n",
        "  device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hS2YU_nD4gyg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\Desktop\\envs\\.council-rag\\.council-rag\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alber\\.cache\\huggingface\\hub\\models--HIT-TMG--KaLM-embedding-multilingual-mini-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "# using huggingface tokenizer for attettion layer\n",
        "# make sure you have GPU enabled\n",
        "# takes around 5 mins to load with TPUs\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model_id = \"HIT-TMG/KaLM-embedding-multilingual-mini-v1\" # which model to use?\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
        "model = AutoModel.from_pretrained(model_id).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gppC6FUl92qV",
        "outputId": "81ca7103-cc07-437a-86df-67c3d504c56b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2Model(\n",
              "  (embed_tokens): Embedding(151936, 896)\n",
              "  (layers): ModuleList(\n",
              "    (0-23): 24 x Qwen2DecoderLayer(\n",
              "      (self_attn): Qwen2Attention(\n",
              "        (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "        (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "        (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "        (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "      )\n",
              "      (mlp): Qwen2MLP(\n",
              "        (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "        (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "        (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    )\n",
              "  )\n",
              "  (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "  (rotary_emb): Qwen2RotaryEmbedding()\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRgyr7oN4gyg"
      },
      "source": [
        "- text enriching with VLLM to add a little description of tables before hey appear?\n",
        "\n",
        "- embeddings that return attention layer\n",
        "\n",
        "- perform similarity on the attention layer -> cluster similar sentences\n",
        "\n",
        "- summarize the clusters\n",
        "\n",
        "- tree-based graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GgAqGk6DSVO"
      },
      "source": [
        "## Splitting the text into sentences and paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wKRiK15oDdgY"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"fr_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qn1F7NekDqc1"
      },
      "outputs": [],
      "source": [
        "doc = nlp(markdown_example)\n",
        "sents = [sent.text for sent in doc.sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVcXDS4_EYwr",
        "outputId": "27d15748-3b35-4c27-e40d-481bbfe3a8bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['#',\n",
              " 'Séance publique\\n\\n\\n\\n',\n",
              " '# du jeudi 28 octobre 2021\\n\\n\\n\\n',\n",
              " '# à 18h00\\n\\n\\n\\n#',\n",
              " 'Chorum',\n",
              " 'Alain Gilles',\n",
              " '- Halle Vacheresse\\n\\n\\n\\n',\n",
              " '#',\n",
              " 'Rue des Vernes à Roanne\\n\\n\\n\\n',\n",
              " '#']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sents[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CY9hPOfbsCL",
        "outputId": "0a5d517c-eac1-465d-acd4-fadc54eef3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of sents:  905\n",
            "Number of final chunks:  91\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# to reconstruct based on sentences, we can iterate through the list with a range and\n",
        "# concat every 10 sents into a single string\n",
        "\n",
        "rang_sentence_union = np.arange(start=0, stop=len(sents), step=10)\n",
        "# print(rang)\n",
        "print(\"Total number of sents: \", len(sents))\n",
        "print(\"Number of final chunks: \", len(rang_sentence_union))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_QMgODsdbf9-"
      },
      "outputs": [],
      "source": [
        "paragraphs = []\n",
        "i = 0\n",
        "\n",
        "# merging sentences based on the ranges\n",
        "while i+1 < len(rang_sentence_union):\n",
        "  start = rang_sentence_union[i]\n",
        "  stop = rang_sentence_union[i+1]\n",
        "  # print(start, stop)\n",
        "\n",
        "  subset_to_join = sents[start : stop]\n",
        "  sent_union = \" \".join(subset_to_join)\n",
        "\n",
        "  paragraph_info = {\"paragraph_union\": sent_union,\n",
        "                    \"start_range\": start,\n",
        "                    \"stop_range\": stop,\n",
        "                    \"list_sents\":subset_to_join}\n",
        "\n",
        "  paragraphs.append(paragraph_info)\n",
        "\n",
        "  i += 1\n",
        "\n",
        "# if the stop of the range comes before the last sentence, we take those final couple of sentences\n",
        "# and add them to the last sentence of the paragraph list\n",
        "\n",
        "if stop != len(sents):\n",
        "\n",
        "  subset_to_join = sents[stop : len(sents)]\n",
        "  final_sents = \" \".join(subset_to_join)\n",
        "  para_to_edit = paragraphs.pop(-1)\n",
        "  final_union = para_to_edit[\"paragraph_union\"] + \" \" + final_sents\n",
        "\n",
        "  para_to_edit[\"paragraph_union\"] =  final_union\n",
        "  para_to_edit[\"stop_range\"] = len(sents)\n",
        "  para_to_edit[\"list_sents\"].extend(subset_to_join)\n",
        "\n",
        "  paragraphs.append(para_to_edit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vc93a6PgdPl",
        "outputId": "576b056b-8fae-4b0d-b16a-0bbc88b8ba4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'paragraph_union': 'Ajustement de la contribution au titre des eaux pluviales pour l\\x92opération Foch Sully (-400 k\\x80), des contributions au SEEDR pour le traitement des ordures ménagères (-189,84 k\\x80), des participations du budget général aux budgets annexes (48,5 k\\x80), de subventions diverses (19,4 k\\x80), des créances admises en non-valeur (-12 k\\x80) et changement de nature comptable (et de chapitre) à la demande de la trésorerie (57 k\\x80).\\n\\n\\n\\n # Charges exceptionnelles : 54 139 \\x80\\n\\n\\n\\nDépenses liées au fonctionnement du Centre de vaccination au Fuyant pour la période du 1er septembre au 31 décembre 2021 (80 k\\x80), changement de nature comptable (et de chapitre) à la demande de la trésorerie (-57 k\\x80), ajustement des dépenses liées au COVID (-9,78 k\\x80), remboursement des abonnements et cours au Nauticum (8 k\\x80), reversement du résultat de la commune Les Noës à la Roannaise de l\\x92Eau (2,8 k\\x80) et de divers dépenses exceptionnelles (30,119 k\\x80).\\n\\n\\n\\n # Dotations aux amortissements et aux provisions : 47 000 \\x80\\n\\n\\n\\n Ajustement provision pour dépréciation des actifs circulants (-26 k\\x80) et provision pour Compte Epargne Temps (73 k\\x80).\\n\\n\\n\\n # Virement à la section d\\x92investissement : 118 500 \\x80\\n\\n\\n\\n(autofinancement complémentaire)\\n\\n\\n\\n # Recettes :\\n\\n\\n\\n# Produits des services : -257 140 \\x80\\n\\n\\n\\n Il s\\x92agit principalement de la diminution des recettes du Nauticum en raison du COVID et de la mauvaise météo de cet été (-300 k\\x80) et des billetteries Pleine nature (-42,14 k\\x80) et culturelles (-41,47 k\\x80), d\\x92un complément pour les revenus des coupes de bois (59,07 k\\x80) et à l\\x92ajustement de refacturations (67,4 k\\x80).\\n\\n\\n\\n # Impôts et taxes : 3 600 \\x80\\n\\n\\n\\nAjustement du reversement des taxes foncières par la commune de Mably sur les bâtiments situés dans la ZAC de Mably.\\n\\n\\n\\n# Subventions - Dotations : -45 060 \\x80\\n\\n\\n\\n Ajustement',\n",
              " 'start_range': np.int64(890),\n",
              " 'stop_range': 905,\n",
              " 'list_sents': ['Ajustement de la contribution au titre des eaux pluviales pour l\\x92opération Foch',\n",
              "  'Sully (-400 k\\x80), des contributions au SEEDR pour le traitement des ordures ménagères (-189,84 k\\x80), des participations du budget général aux budgets annexes (48,5 k\\x80), de subventions diverses (19,4 k\\x80), des créances admises en non-valeur (-12 k\\x80) et changement de nature comptable (et de chapitre) à la demande de la trésorerie (57 k\\x80).\\n\\n\\n\\n',\n",
              "  '# Charges exceptionnelles : 54 139 \\x80\\n\\n\\n\\nDépenses liées au fonctionnement du Centre de vaccination au Fuyant pour la période du 1er septembre au 31 décembre 2021 (80 k\\x80), changement de nature comptable (et de chapitre) à la demande de la trésorerie (-57 k\\x80), ajustement des dépenses liées au COVID (-9,78 k\\x80), remboursement des abonnements et cours au Nauticum (8 k\\x80), reversement du résultat de la commune',\n",
              "  'Les Noës à la Roannaise de l\\x92Eau (2,8 k\\x80) et de divers dépenses exceptionnelles (30,119 k\\x80).\\n\\n\\n\\n',\n",
              "  '# Dotations aux amortissements et aux provisions : 47 000 \\x80\\n\\n\\n\\n',\n",
              "  'Ajustement provision pour dépréciation des actifs circulants (-26 k\\x80) et provision pour Compte Epargne Temps (73 k\\x80).\\n\\n\\n\\n',\n",
              "  '#',\n",
              "  'Virement à la section d\\x92investissement : 118 500 \\x80\\n\\n\\n\\n(autofinancement complémentaire)\\n\\n\\n\\n',\n",
              "  '#',\n",
              "  'Recettes :\\n\\n\\n\\n#',\n",
              "  'Produits des services : -257 140 \\x80\\n\\n\\n\\n',\n",
              "  'Il s\\x92agit principalement de la diminution des recettes du Nauticum en raison du COVID et de la mauvaise météo de cet été (-300 k\\x80) et des billetteries Pleine nature (-42,14 k\\x80) et culturelles (-41,47 k\\x80), d\\x92un complément pour les revenus des coupes de bois (59,07 k\\x80) et à l\\x92ajustement de refacturations (67,4 k\\x80).\\n\\n\\n\\n',\n",
              "  '# Impôts et taxes : 3 600 \\x80\\n\\n\\n\\nAjustement du reversement des taxes foncières par la commune de Mably sur les bâtiments situés dans la ZAC de Mably.\\n\\n\\n\\n# Subventions',\n",
              "  '- Dotations : -45 060 \\x80\\n\\n\\n\\n',\n",
              "  'Ajustement']}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paragraphs[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_markdown_to_paras(text, spacy_model=\"fr_core_news_sm\", n_sents_per_para=10):\n",
        "    \n",
        "    nlp = spacy.load(spacy_model)\n",
        "    doc = nlp(text)\n",
        "    sents = [sent.text for sent in doc.sents]\n",
        "    \n",
        "    rang_sentence_union = np.arange(start=0, stop=len(sents), step=n_sents_per_para)\n",
        "    # print(\"Total number of sents: \", len(sents))\n",
        "    # print(\"Number of final chunks: \", len(rang_sentence_union))\n",
        "\n",
        "\n",
        "    paragraphs = []\n",
        "    i = 0\n",
        "\n",
        "    # merging sentences based on the ranges\n",
        "    while i+1 < len(rang_sentence_union):\n",
        "        start = rang_sentence_union[i]\n",
        "        stop = rang_sentence_union[i+1]\n",
        "        # print(start, stop)\n",
        "\n",
        "        subset_to_join = sents[start : stop]\n",
        "        sent_union = \" \".join(subset_to_join)\n",
        "\n",
        "        paragraph_info = {\"paragraph_union\": sent_union,\n",
        "                        \"start_range\": start,\n",
        "                        \"stop_range\": stop,\n",
        "                        \"list_sents\":subset_to_join}\n",
        "\n",
        "        paragraphs.append(paragraph_info)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    # if the stop of the range comes before the last sentence, we take those final couple of sentences\n",
        "    # and add them to the last sentence of the paragraph list\n",
        "    if stop != len(sents):\n",
        "\n",
        "        subset_to_join = sents[stop : len(sents)]\n",
        "        final_sents = \" \".join(subset_to_join)\n",
        "        para_to_edit = paragraphs.pop(-1)\n",
        "        final_union = para_to_edit[\"paragraph_union\"] + \" \" + final_sents\n",
        "\n",
        "        para_to_edit[\"paragraph_union\"] =  final_union\n",
        "        para_to_edit[\"stop_range\"] = len(sents)\n",
        "        para_to_edit[\"list_sents\"].extend(subset_to_join)\n",
        "        paragraphs.append(para_to_edit)\n",
        "        \n",
        "    return paragraphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7WlBNr2gm8c"
      },
      "source": [
        "Now we have a list of dictionaries, one for each constructed paragraph. So far, each paragraph has the union string, start and end indexes as well as the list of individual sentences that were joined."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_QjccTUBASV"
      },
      "source": [
        "## Getting the text embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc1xqf1_IC-t"
      },
      "source": [
        "NOTE: There is one important caveat. We are computing sentence embeddings. If we were to pass the whole doc, the attention mask for each token would look very different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2IsSD5IEm62"
      },
      "source": [
        "### Example for one piece of text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8grmXscv4gyg"
      },
      "outputs": [],
      "source": [
        "# dir(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oXyC3J8g4gyg"
      },
      "outputs": [],
      "source": [
        "tokenized_markdown = tokenizer(markdown_example, return_tensors=\"pt\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqfU1Njp_T0B",
        "outputId": "bffac6ae-a815-4542-bcbb-7f7d4725e691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20468"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_markdown[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mvm7hSEq4gyg"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  # first batch (only one since we are processing one doc)\n",
        "  # final token\n",
        "    embeddings = model(**tokenized_markdown)[0][:, 0].squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaO-j34G_OeG",
        "outputId": "9f690874-398d-4de4-e5ac-f94803ff4417"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([896])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfe2cySo_fGQ"
      },
      "source": [
        "We take the last token since it's the one which contains all the aggregate info?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "r9Dz0XGjCnOC"
      },
      "outputs": [],
      "source": [
        "# embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CZN2u5nI4gyh"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "normalized_embeddings = F.normalize(embeddings, p=2, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "75kj1dKJA4Uq"
      },
      "outputs": [],
      "source": [
        "# normalized_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDRe1uk9Es4x"
      },
      "source": [
        "### For a list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OFOd5PChE7i_"
      },
      "outputs": [],
      "source": [
        "def compute_norm_embeddings(tokenizer, model, sentence):\n",
        "\n",
        "    tokenized_sentences = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokenized_sentences)[0][:, 0].squeeze(0) # to take out the unused dimension since we are not batching\n",
        "        # print(embeddings.shape)\n",
        "\n",
        "    normalized_embeddings = F.normalize(embeddings, p=2, dim=0)\n",
        "    detached_embeddings = normalized_embeddings.detach().cpu().numpy() # detached into cpu so that we can manipulate them for clustering\n",
        "\n",
        "    torch.cuda.empty_cache() # careful with running out of memory\n",
        "\n",
        "    return detached_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8_SapulEFWyk"
      },
      "outputs": [],
      "source": [
        "list_paras = [para[\"paragraph_union\"] for para in paragraphs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cBZZuOCjix2e"
      },
      "outputs": [],
      "source": [
        "for paras, para_dict in zip(list_paras, paragraphs):\n",
        "    para_dict[\"para_embedding\"] = compute_norm_embeddings(tokenizer, model, paras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxS_QG8GiTj",
        "outputId": "83cfc46e-afee-4b64-881a-619aa8f1d6d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(896,)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paragraphs[0][\"para_embedding\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmGM9H8VlrGF"
      },
      "source": [
        "Now there is an extra key for the embeddings that we will use for the clsutering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSc1QSlJGloT"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "90kGMssB5sJq"
      },
      "outputs": [],
      "source": [
        "squeezeded_embeddings = [para_dict[\"para_embedding\"] for para_dict in paragraphs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "QolXy-Qc6MRu"
      },
      "outputs": [],
      "source": [
        "# squeezeded_embeddings[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-Od8pg7Idk"
      },
      "source": [
        "### Example for one number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Z5bNPk2o7yHR"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "W5XFk-ac5OEL"
      },
      "outputs": [],
      "source": [
        "gm = GaussianMixture(n_components=4, random_state=42)\n",
        "clusters = gm.fit_predict(squeezeded_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Hy--nqom6Z_l"
      },
      "outputs": [],
      "source": [
        "# clusters # label assigned to each sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF4VmocF6lgg",
        "outputId": "0cbb3cbd-b498-434e-d180-a9bf52fc2244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.44329956\n"
          ]
        }
      ],
      "source": [
        "sil_sc = silhouette_score(squeezeded_embeddings, clusters)\n",
        "print(sil_sc) # the closer to 1 the better (how similar is an object to its cluster compared to the other clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T89-GhBlkiPU",
        "outputId": "ed95ccdf-cc62-4c1b-9e59-9fa459199c8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 3, 0, 0, 0, 2, 0, 1, 1, 1,\n",
              "       0, 3, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 3, 1, 0, 1,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1,\n",
              "       1, 0])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT9ds5aY7Kdu"
      },
      "source": [
        "### Optimal number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reomAYOP7Okn",
        "outputId": "48de469f-eae9-41ea-c849-359308d24c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3 4 5 6 7 8]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# initial number of clusters to try\n",
        "range_clusters = np.arange(start=3, stop=9, step=1)\n",
        "print(range_clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQcSWEgK_4HA"
      },
      "source": [
        "We could compute jensenshannon distance as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "coeaWSg63QUT"
      },
      "outputs": [],
      "source": [
        "def cluster_n(cluster_model, n_clusters, embeddings, scoring_function):\n",
        "\n",
        "  clusters = cluster_model.fit_predict(embeddings)\n",
        "  sil_sc = scoring_function(embeddings, clusters)\n",
        "\n",
        "  print(\"Number of clusters: \", n_clusters)\n",
        "  print(\"Score: \", sil_sc)\n",
        "  print()\n",
        "\n",
        "  return clusters, sil_sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8LKJOTk4ZDi",
        "outputId": "d391e4ee-76d5-4311-a970-ac0db4efed1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clusters:  3\n",
            "Score:  0.44600135\n",
            "\n",
            "Number of clusters:  4\n",
            "Score:  0.44329956\n",
            "\n",
            "Number of clusters:  5\n",
            "Score:  0.47113436\n",
            "\n",
            "Number of clusters:  6\n",
            "Score:  0.48168555\n",
            "\n",
            "Number of clusters:  7\n",
            "Score:  0.48469815\n",
            "\n",
            "Number of clusters:  8\n",
            "Score:  0.5539949\n",
            "\n"
          ]
        }
      ],
      "source": [
        "silhouette_scores = []\n",
        "clusters_labels = []\n",
        "for n_cluster in range_clusters:\n",
        "  gm = GaussianMixture(n_components=n_cluster, random_state=42)\n",
        "  clusters, sil_sc = cluster_n(gm, n_cluster, squeezeded_embeddings, silhouette_score)\n",
        "  silhouette_scores.append(sil_sc)\n",
        "  clusters_labels.append(clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLWh2rQz8RC2",
        "outputId": "05f13a74-d953-4a8d-b115-df7280fcf747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index 5\n",
            "Optimal Number of Clusters 8\n"
          ]
        }
      ],
      "source": [
        "max = np.argmax(silhouette_scores)\n",
        "optimal_n = range_clusters[max]\n",
        "print(\"Index\", max)\n",
        "print(\"Optimal Number of Clusters\", optimal_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "TRylDnIF8lOy"
      },
      "outputs": [],
      "source": [
        "final_clusters = clusters_labels[max]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eIyvmFl9sdO"
      },
      "source": [
        "## Logging Information, concatinating the text relating to each cluster and recomputing embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6q0c0Upr0ec",
        "outputId": "ed377a3d-ef8d-420f-e0f8-70a00f699322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cluster_0': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_1': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_2': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_3': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_4': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_5': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_6': {'para_indexes': [], 'union_paras': ''},\n",
              " 'cluster_7': {'para_indexes': [], 'union_paras': ''}}"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clusters_ids = {f\"cluster_{cluster_id}\": {\"para_indexes\": [],\n",
        "                                        \"union_paras\": \"\"} for cluster_id in np.arange(0, optimal_n, 1)}\n",
        "clusters_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "z0bvr7rLlh9R"
      },
      "outputs": [],
      "source": [
        "# saving the cluster in the paragraphs dictionary\n",
        "# and the indexes of the paragraphs of cluster in another one\n",
        "\n",
        "i = 0\n",
        "\n",
        "for para_dict, cluster in zip(paragraphs, final_clusters):\n",
        "  cluster_n_string = f\"cluster_{cluster}\"\n",
        "  para_dict[\"para_cluster\"] = cluster_n_string\n",
        "  clusters_ids[cluster_n_string][\"para_indexes\"].append(i)\n",
        "  clusters_ids[cluster_n_string][\"union_paras\"] = clusters_ids[cluster_n_string][\"union_paras\"] + para_dict[\"paragraph_union\"]\n",
        "  i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "eNH8LVu-0DAy"
      },
      "outputs": [],
      "source": [
        "# depending on the post-processing techniques, we may not be using these embeddings\n",
        "# and we'll have to re-tokenize and embed with the model we use\n",
        "\n",
        "for cluster in clusters_ids.keys():\n",
        "  text = clusters_ids[cluster][\"union_paras\"]\n",
        "  cluster_embds = compute_norm_embeddings(tokenizer, model, text)\n",
        "  clusters_ids[cluster][\"cluster_embedding\"] = cluster_embds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "c8VHpeFQsDjH"
      },
      "outputs": [],
      "source": [
        "# clusters_ids[\"cluster_0\"]\n",
        "# looking at this example, we can see that the clustering is mostly sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JbkudLLndDi",
        "outputId": "69eb8213-17c6-444b-bff0-01bd0f55bd45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['paragraph_union', 'start_range', 'stop_range', 'list_sents', 'para_embedding', 'para_cluster'])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paragraphs[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3ioP6aysXKk",
        "outputId": "67205a2b-a824-40c3-987f-c9d36bcb1f75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['cluster_0', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6', 'cluster_7'])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clusters_ids.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IROnueIHz1X4",
        "outputId": "cfae2080-ca03-482f-bfd1-2d3a5b8f1804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['para_indexes', 'union_paras', 'cluster_embedding'])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clusters_ids[\"cluster_0\"].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cPNekAS_KqF"
      },
      "source": [
        "RECAP\n",
        "\n",
        "So far we have:\n",
        "- the reconstructed text based on the paragraph clusters.\n",
        "- the embeddings of the reconstructed clusters.\n",
        "- the reconstructed paragraphs in ranges of 10 sentences.\n",
        "- the embeddings of the paragraphs detached and squeezed.\n",
        "- the cluster each paragraph belongs to.\n",
        "- the indexes of the paragraphs of each cluster.\n",
        "- the actual sentences split from SpaCy, in case we need them after.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sea9FktX1Vk2"
      },
      "source": [
        "LEFT TO DO FOR THE PREPROCESS: GET THE NUMBER/TABLES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQcVT6oq5E5R"
      },
      "source": [
        "## Sumarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQfcKOHADIRo"
      },
      "source": [
        "Now that we have the basic separation wrt to clusters, we can start creating different representations for each cluster and doing the hierarchical indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting protobuf\n",
            "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Installing collected packages: protobuf\n",
            "Successfully installed protobuf-5.29.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "poc255oq5Gri"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\Desktop\\envs\\.council-rag\\.council-rag\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "summ_model = 'csebuetnlp/mT5_multilingual_XLSum' # take the one for mt5 french!!\n",
        "\n",
        "tokenizer_summ = AutoTokenizer.from_pretrained(summ_model)\n",
        "model_summ = AutoModelForSeq2SeqLM.from_pretrained(summ_model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "QRtbKqB19P-3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_20020\\3419883012.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip())) # was part of the docs\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip())) # was part of the docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXOhgnCIAeJi"
      },
      "source": [
        "### Individual example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "yUvl3Ogu6l8-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"PROCES VERBAL\\n\\n\\n\\n L'an deux mille vingt et un, le 28 octobre à 18 h 00, les conseillers communautaires de Roannais Agglomération, se sont réunis à l\\x92Espace Chorum \\x96 Halle Vacheresse \\x96 Rue des Vernes à Roanne.\\n\\n\\n\\n La convocation de tous les conseillers a été faite le 22 octobre 2021, dans les formes et délais prescrits par la loi, par Yves Nicolin, Président.\\n\\n\\n\\n # Etaient présents :\\n\\n\\n\\nChristine Aranéo - Marcel AugierDana Burnichon| | |Edmond Bourgeon| |\\n\\n|-| | |Catherine Brun| |\\n\\n|Jean-Marc Detour| | | | |\\n\\n|Daniel Fréchet| | |Lucien Murzi| |\\n\\n|Quentin Guillermin|X| | | |\\n\\n|Jean-Paul Heyberger| | |Christelle Lattat| |\\n\\n|Franck Maupetit| | |Annie Gerenton| |\\n\\n|Patrick Meunier|X| | | |\\n\\n|Nabih Nejjar|X| | |(arrivé en cours de séance)|\\n\\n|Gilles Passot| | |Fabien Lambert|(arrivé en cours de séance)|\\n\\n|Marcel Peuillon|X| | | |\\n\\n|Didier Prunet| | |Christian Dupuis| |\\n\\n|Vickie Redeuilh| | |Hélène Lapalus| |\\n\\n|Marie-Hélène Riamon| | |Denis Vanhecke| |\\n\\n|Corinne Troncy| | |Maryvonne Loughraieb| |\\n\\n|Isabelle Valcourt| | |Jean-Luc Mardeuil|Festival » ;\\n\\n - de préciser que cette demande de subvention a pour objet de soutenir la réalisation du Festival jeune public « Chouet Festival 2022 », dans le cadre de la saison culturelle 2021/2022 et dont le coût s\\x92élève à 84 254 \\x80 TTC.\\n\\n\\n\\n # N° DP 2021-314 du 15 septembre 2021 - Clôture de la régie de recettes et d\\x92avances du Centre de Loisirs Ados au 15 septembre 2021 - Abrogation décision du Président n° DP 2016-237 du 30 août 2016\\n\\n\\n\\n Le Président décide :\\n\\n\\n\\n - d\\x92abroger la décision du Président n° DP 2016-237 du 30 août 2016 et de clôturer au 15 septembre 2021 la régie de recettes et d\\x92avances du Centre de loisirs ados ;\\n\\n - de dire que Monsieur le Président de Roannais Agglomération et Monsieur le Trésorier de la Trésorerie de Roanne Municipale sont chargés chacun en ce qui les concerne de l\\x92exécution de la présente décision et dont une ampliation sera adressée au régisseur titulaire et aux mandataires suppléants.\\n\\n\\n\\n # N° DP 2021-315 du 15 septembre 2021 - Développement économiqueSerrurerie » des travaux de déconstruction et de construction d\\x92un Bâtiment d\\x92Enseignement Supérieur en vue du regroupement des formations sur le Campus Mendes France à Roanne (Phase 2 : travaux de construction) avec la société ROCHE SARL ;\\n\\n - de préciser que cet avenant a pour objet de prendre en compte des ajustements techniques pour un montant de + 6 047,00 \\x80 HT, correspondant à une plus-value du montant du lot de +9,2%, portant le montant du lot 10 à 71 564,60 \\x80 HT.\\n\\n\\n\\n# N° DP 2021-319 du 20 septembre 2021 - Aéroport - Etude de faisabilité pour la réfection de la piste de l\\x92aéroport de Roanne - Marché avec la société SOGETI INGENIERIE AIRPORTS\\n\\n\\n\\n Le Président décide :\\n\\n\\n\\nAssainissement ».\\n\\n\\n\\n# N° DP 2021-329 du 7 octobre 2021 - Service Solidarités\\n\\n\\n\\nPLIE du Roannais - Facilitateur des clauses sociales d\\x92insertion dans les marchés publics - Convention cadre de coopération avec OPHEOR pour la mise en \\x9cuvre et le suivi des clauses d\\x92insertion dans le cadre des marchés publics\\n\\n\\n\\n Le Président décide :\\n\\n\\n\\n - d\\x92approuver la convention cadre de coopération à intervenir avec OPHEOR ;\\n\\n - de préciser que cette convention de coopération a pour objet de fixer les règles de collaboration entre Roannais Agglomération et OPHEOR, dans le cadre de la mise en \\x9cuvre des clauses sociales d\\x92insertion relative à ses marchés publics.\\n\\n\\n\\n # N° DP 2021-330 du 7 octobre 2021 - Développement économique\\n\\n\\n\\nAéroport de Roanne - Protocole d\\x92accord pour la fourniture de données aéronautiques entre la DSNA et RoannaisAgglomération - Avenant n°1\\n\\n\\n\\n Le Président décide :\\n\\n\\n\\n - d\\x92approuver l\\x92avenant n° 1 au protocole d\\x92accord pour la fourniture de données aéronautiques, entre la Direction des Services de la Navigation Aérienne et Roannais Agglomération, gestionnaire de l\\x92Aéroport de Roanne ;\\n\\n - de préciser que ce protocole d\\x92accord a pour objet l\\x92ajout de la responsabilité des exploitants dans la diffusion des données du Global Reporting Format, GRF, et de définir les modalités de transmission des données relatives à l\\x92état des surfaces de l\\x92aire de mouvement sous le nouveau format des SNOWTAM.\\n\\n\\n\\n # N° DP 2021-331 du 7 octobre 2021 - Développement économique\\n\\n\\n\\nAéroport de Roanne - Convention de mise à disposition de solution logicielle pour la gestion des vols de drones - Société CLEARANCE\\n\\n\\n\\n Le Président décide :\\n\\n\\n\\nAEROPORT - Site aéroportuaire de Roanne Bâtiment à réhabiliter « Fox - Trot » : Convention d\\x92occupation temporaire du domaine public aéroportuaire constitutive de droits réels avec la société SUPERBE AILE FORMATION\\n\\n\\n\\n Le bureau communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\nAccorde à la société SUPERBE AILE FORMATION, société par action simplifiée, ayant son siège social 1015 Route de Combray 42155 Saint-Léger-Sur-Roanne, l\\x92occupation du bâtiment à réhabiliter dénommé « FoxNauticum » situé rue Général Giraud à Roanne ;\\n\\n - Précise que cette résiliation est convenue sans aucune indemnité de part et d\\x92autre ;\\n\\n - Approuve l\\x92acte bilatéral de résiliation amiable ;\\n\\n - Autorise Monsieur le Président ou son représentant dûment habilité à effectuer toutes les actions se rapportant à l\\x92exécution de cette délibération.\\n\\n\\n\\n # N° DBC 2021-084 - Stratégies et ressources foncières - Saint-Germain-Lespinasse - Zone d\\x92activités «n° 37 sis 739 route de la Mirandole à Villerest dont le montant est estimé à 42 030,20 \\x80 HT ;\\n\\n\\n\\n - dit que le prix d\\x92acquisition est désormais fixé à 270 420,00 \\x80 sur lequel la TVA pourra être appliquée sur la totalité ou en partie, après vérification du régime fiscal applicable ;\\n\\n\\n\\n - autorise Monsieur le Président, ou son représentant dûment habilité, à signer les actes à intervenir relatif à la vente du bien, et toutes pièces nécessaires à la finalisation de cette opération.\\n\\n\\n\\n # N° DBC 2021-086 - Aménagement du territoireMonsieur le Président, ou son représentant, à transmettre le dossier correspondant à la Région Auvergne Rhône - Alpes , celle-ci pouvant accorder une aide de 20 % en complément.\\n\\n\\n\\n Page 8 sur 49\\n\\n\\n\\n# N° DBC 2021-090 - Développement économique\\n\\n\\n\\n Subvention au titre de l\\x92aide au développement des petites entreprises du commerce, de l\\x92artisanat et des services avec point de vente - Subvention à l\\x92établissement Boulangerie Pâtisserie CUCHERAT Renaison\\n\\n\\n\\nVignobles Forez Roannais , Aux Racines de la Loire»\\n\\n\\n\\n Le bureau communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\n - attribue une subvention de 5 500 \\x80 à l\\x92association « Vignobles Forez Roannais , Aux Racines de la Loire », pour le territoire du vignoble Roannais ;\\n\\n - dit que les crédits sont prévus au budget général - chapitre 65.\\n\\n\\n\\n# N° DBC 2021-0951 « compétence petite enfance » , lot 2 « secteur Nord-Ouest »)\\n\\n\\n\\nLe bureau communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\n - approuve les accords -cadres mono-attributaires à bons de commande pour les prestations de maintenance des installations de chauffage, de climatisation, de ventilation et de production d\\x92eau chaude sanitaire des sites de Roannais Agglomération comme suit :\\n\\n\\n\\n|N° et dénomination du lot|Attributaire(s) sous réserve transmission des PAA|Montant contractuel et rappel des montants minimum et maximum de l\\x92accord-cadre|Montant P2+P3 estimatif non-contractuel \\x80 HT sur la durée de 3 ans (à titre d\\x92information)|\\n\\n|---|---|---|---|\\n\\n|Lot 1 : Compétence Petite enfance|HERVE THERMIQUE|Sans montant minimum et montant maximum de 35 000 \\x80 HT sur la durée du marché de 3 ans|34 995 \\x80 HT|\\n\\n|Lot 2 : Secteur Nord-Ouest|HERVE THERMIQUE|Sans montant minimum et montant maximum de 26 000 \\x80 HT sur la durée du marché de 3 ans|16 365 \\x80 HT|\\n\\n\\n\\n Le bureau communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\nMonsieur le Président ou son représentant à intervenir dans l'exécution et le règlement dudit marché ;\\n\\n - dit que les dépenses seront prélevées sur les crédits ouverts à cet effet au budget général, section de fonctionnement ;\\n\\n - dit que les recettes liées à la refacturation à Mably, Riorges, Roanne et Villerest seront prévues au budget général, section de fonctionnement.\\n\\n\\n\\n # N° DBC 2021-102 - Mutualisation - Avenant n°1 à la convention de prestation de services pour l\\x92organisation de sessions de formation entre Roannais Agglomération et Ambierle, Mably, OPHEOR, Ouches, Pouilly-les-Nonains, Roannaise de l\\x92Eau, Renaison, Riorges, Saint-Martin-d\\x92Estreaux, Saint-Romain-La-Motte, Saint-Alban-les-Eaux, Saint-André-d\\x92Apchon et Villerest\\n\\n\\n\\n Le bureau communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\n - approuve l\\x92avenant n°1 aux conventions de prestation de services pour l\\x92organisation de sessions de formation entre Roannais Agglomération et Ambierle, Mably, OPHEOR, Ouches, Pouilly-les-Nonains, Roannaise de l\\x92Eau, Renaison, Riorges, Saint-Martin-d\\x92Estreaux, Saint-Romain-La-Motte, Saint-Alban-les-Eaux, Saint-André-d\\x92Apchon et VillerestL\\x92AUDACIEUSE LINGERIE Renaison\\n\\n\\n\\n Le bureau communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\n - attribue une subvention à l\\x92établissement L\\x92AUDACIEUSE LINGERIE, représenté par Mme Laëtitia SYBELIN, située sur la commune de Renaison, pour un montant de 3 383,00 \\x80 maximum, représentant 10 % des dépenses éligibles ;\\n\\n - autorise Monsieur le Président, ou son représentant, à transmettre le dossier correspondant à la Région Auvergne Rhône - Alpes , celle-ci pouvant accorder une aide de 20 % en complément.\\n\\n\\n\\nRapport d\\x92activités 2020\\n\\n\\n\\n Monsieur le Président présente les grandes lignes du rapport d\\x92activité 2020.\\n\\n\\n\\n « L\\x92année 2020 a été marquée par :\\n\\n\\n\\n- le renouvellement des exécutifs communaux (mars et juin) et intercommunal (juillet),\\n\\n- le COVID, avec la crise sanitaire et économique.\\n\\n\\n\\n La priorité a donc été donnée à l\\x92économie avec notamment :\\n\\n\\n\\n - la mise en place d\\x92un fonds de soutien aux entreprises,\\n\\n - la mise en place d\\x92une aide au secteur du tourisme,\\n\\n - la mobilisation des services en faveur de la protection des soignants et des personnes,\\n\\n - la poursuite du service public : ordures ménagères notamment.\\n\\n\\n\\nEn parallèle, nous avons tant bien que mal poursuivi nos actions dans les différents domaines de compétence. Les nouveautés de l\\x92année 2020 sont :\\n\\n\\n\\n- Transport : attribution de la DSP Transport à Transdev (flotte électrique),\\n\\ngaz à effet de serre », une seule fois le mot « pollution », une fois le mot « biodiversité », mais deux fois le mot « faune » , une fois le mot « flore » , quatre fois le mot « nature » et cinq fois seulement le mot« climat », là où dans le même temps, il y avait 40 fois le mot « économie », 23 fois le mot « attractivité » , 70 fois le mot « entreprise » , 22 fois le mot « Euros ». Voilà qui montre pour moi, qui donne une couleur et une indication sur les orientations qui sont prises.\\n\\n\\n\\nNéanmoins, restez quand même objectif, et comparez avec ce qui se passe ailleurs. D'ailleurs, je vais m'amuser, à la fin du mandat, à faire des comparaisons avec des agglomérations de taille comparable qui sont dirigées par des gens de votre sensibilité. On verra effectivement si les bilans présentés par vos amis sont aussi flatteurs que ceux que nous pourrons nous mêmes présenter. Après, bien évidemment que l'aéroport consomme des carburants. Mais, Monsieur Beysson, chaque fois que vous mettez en marche votre micro, vous consommez de l'électricité, de l'énergie. Donc, si vous voulez en consommer moins, abstenez-vous. On en est tous là, nous utilisons tous des moyens. Effectivement, l'aviation utilise des avions, ces avions brûlent du kérosène. Néanmoins, ce que je remarque, c'est qu'aujourd'hui il y a des fabricants d'avions européens qui sont sur des productions d'aéronefs, qui eux-aussi font des efforts pour consommer moins de carburant\\x85 On ne vous dit pas que nous vivons dans un monde merveilleux mais je pense que notre pays, je dis bien notre pays, je ne parle pas de l'agglomération, n'a pas à rougir de ce qui se passe par rapport à tout le reste du monde. Si vous pensez qu'on va sauver la planète uniquement à partir de Roanne, je pense malheureusement que les jours nous sont comptés ».\\n\\n\\n\\nPage 14 sur 49\\n\\n\\n\\nFranck Beysson répond «Considérant qu\\x92au 31 décembre 2020, une provision totale de 308 726 \\x80 tous budgets confondus a été constituée et que la valorisation des CET en 2021 s\\x92élève à 370 966 \\x80, il y a donc lieu d\\x92ajuster la provision par budget selon le tableau ci-dessous :\\n\\n\\n\\n|MONTANT PROVISION FIN D'EXERCICE 2020|REPRISE DE L'EXERCICE|DOTATION DE L'EXERCICE 2021|PROVISION FIN D'EXERCICE 2021|\\n\\n |---|---|---|---|\\n\\n|BUDGET GENERAL|285 517|72 848|358 365|\\n\\n|BUDGET ASSAINISSEMENT|9 035|9 035|0|\\n\\n|BUDGET EQUIPEMENT DE|12 486|853|11 633|\\n\\n\\n\\n# TOURISME ET LOISIRS\\n\\n\\n\\n # BUDGET\\n\\n\\n\\n|TRANSPORTS|1 688|720|968| |\\n\\n|---|---|---|---|---|\\n\\n|TOTAL|308 726|10 608|72 848|370 966|\\n\\n\\n\\n Le Conseil communautaire, après en avoir délibéré à l\\x92unanimité :\\n\\n\\n\\nMise en place du compostage collectif\\n\\n\\n\\n Mettre en place du compostage collectif, là où c'est possible et là où c\\x92est organisable, parce que c'est une technique qui nécessite d'être particulièrement vigilant et particulièrement motivé. Il y a donc un travail de communication et de suivi de ces sites ;\\n\\n\\n\\n Mettre en place, sur une partie du territoire, la collecte en porte à porte de la fraction fermentescible. L\\x92issue de ces déchets fermentescibles, ce sera le compostage, c\\x92est sûr, soit individuel, soit pour la collecte sélective qui se fera dans une entreprise spécialisée, de façon à ce qu\\x92on ait un retour au sol le plus rapide possible ; ce qui n'est pas possible lorsqu'on fait un tri de la matière fermentescible depuis un centre de tri qui extrait ces matières fermentescibles des ordures ménagères, du fait d\\x92un risque de pollution. C\\x92est donc pour cela que le tri à la source va être exigé dès 2024. Normalement, nous serons en ordre de marche, dès janvier 2023. Vous dire aujourd\\x92hui le nombre de composteurs individuels, collectifs, et la part qui sera réellement collectée en porte à porte est encore un petit peu tôt. Il va falloir attendre les résultats de l'enquête, de façon à ajuster au mieux par rapport au territoire.\\n\\n\\n\\nM. le Président ajoute que la prochaine Commission Environnement aura lieu le 17 novembre 2021 et qu\\x92elle se penchera sur ces projets .\\n\\n\\n\\n# Franck Beysson s\\x92interroge\\n\\n\\n\\n Franck Beysson s\\x92interroge sur une éventuelle réflexion portant sur une plateforme de recyclage, en local, des matières pour raccourcir les distances et éviter des chaines d\\x92envoi lointaines . Jean-Yves Boire répond que pour l\\x92instant quelque chose existe. Il y a des ateliers solidaires, situés à Riorges, mais l\\x92ensemble des matériaux ne peut pas être intégré à ce type d\\x92activité car il y a une multitude de filières et ce serait très compliqué de gérer tout cela en local. Il explique que des choses se font et qu\\x92elles risquent effectivement d'évoluer dans le cadre de cette évolution de collecte.Aucune nouvelle plateforme n\\x92est prévue pour l'instant, hormis le projet du SEEDR, le Syndicat de traitement des déchets du Nord du département, où là une usine multi filières est prévue, de façon à ce que les déchets résiduels qui se trouvent dans le bac des ordures ménagères - « On sait qu'aujourd'hui on a encore 70 % de ces déchets qui ne devraient pas s'y trouver- », mais avec l'extension des consignes de tri, avec l'évolution des systèmes de collecte, cela devrait baisser. Jean-Yves Boire ajoute qu\\x92il y aura encore beaucoup à faire et que c'est bien le but de cette usine de tri que de séparer les matériaux, de façon à les mettre dans les bonnes filières et que l'on puisse en recycler un maximum. Il explique que ceux-ci seront soit recyclés, soit leur énergie sera récupérée car ils présentent l'avantage d'avoir un pouvoir calorifique inférieur (PCI) qui viendrait se substituer à l'utilisation de l'énergie fossile. C\\x92est ce que l\\x92on appelle les combustibles solides de récupération.\\n\\n\\n\\n # Conseil communautaire\\n\\n\\n\\nLe Conseil communautaire, après en avoir délibéré, avec 76 voix pour, 0 contre et 2 abstentions :\\n\\n\\n\\n- Approuve la création de l\\x92autorisation de programme 1040 intitulée « Réorganisation collecte déchets ménagers » sur le budget général pour un montant global de 9 000 000 \\x80 et la répartition prévisionnelle des crédits de paiement sur la période 2021-2025 comme suit :\\n\\n\\n\\n|Millésime|N° AP|Montant|CP 2021|CP 2022|CP 2023|CP 2024|CP 2025|\\n\\n|---|---|---|---|---|---|---|---|\\n\\n|2021|1040|9 000 000 \\x80|200 000 \\x80|5 600 000 \\x80|2 000 000 \\x80|600 000 \\x80|600 000 \\x80|\\n\\n\\n\\nIndique que les crédits de paiement (CP) de 2021 d\\x92un montant de 200 000 \\x80 seront inscrits à la prochaine Décision Modificative sur le Budget Général.\\n\\n\\n\\n# 5. Décision modificativeAjustement de la contribution au titre des eaux pluviales pour l\\x92opération Foch Sully (-400 k\\x80), des contributions au SEEDR pour le traitement des ordures ménagères (-189,84 k\\x80), des participations du budget général aux budgets annexes (48,5 k\\x80), de subventions diverses (19,4 k\\x80), des créances admises en non-valeur (-12 k\\x80) et changement de nature comptable (et de chapitre) à la demande de la trésorerie (57 k\\x80).\\n\\n\\n\\n # Charges exceptionnelles : 54 139 \\x80\\n\\n\\n\\nDépenses liées au fonctionnement du Centre de vaccination au Fuyant pour la période du 1er septembre au 31 décembre 2021 (80 k\\x80), changement de nature comptable (et de chapitre) à la demande de la trésorerie (-57 k\\x80), ajustement des dépenses liées au COVID (-9,78 k\\x80), remboursement des abonnements et cours au Nauticum (8 k\\x80), reversement du résultat de la commune Les Noës à la Roannaise de l\\x92Eau (2,8 k\\x80) et de divers dépenses exceptionnelles (30,119 k\\x80).\\n\\n\\n\\n # Dotations aux amortissements et aux provisions : 47 000 \\x80\\n\\n\\n\\n Ajustement provision pour dépréciation des actifs circulants (-26 k\\x80) et provision pour Compte Epargne Temps (73 k\\x80).\\n\\n\\n\\n # Virement à la section d\\x92investissement : 118 500 \\x80\\n\\n\\n\\n(autofinancement complémentaire)\\n\\n\\n\\n # Recettes :\\n\\n\\n\\n# Produits des services : -257 140 \\x80\\n\\n\\n\\n Il s\\x92agit principalement de la diminution des recettes du Nauticum en raison du COVID et de la mauvaise météo de cet été (-300 k\\x80) et des billetteries Pleine nature (-42,14 k\\x80) et culturelles (-41,47 k\\x80), d\\x92un complément pour les revenus des coupes de bois (59,07 k\\x80) et à l\\x92ajustement de refacturations (67,4 k\\x80).\\n\\n\\n\\n # Impôts et taxes : 3 600 \\x80\\n\\n\\n\\nAjustement du reversement des taxes foncières par la commune de Mably sur les bâtiments situés dans la ZAC de Mably.\\n\\n\\n\\n# Subventions - Dotations : -45 060 \\x80\\n\\n\\n\\n Ajustement\""
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_cluster = clusters_ids[\"cluster_0\"][\"union_paras\"]\n",
        "example_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "iao1G9ap983n"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "tokenized_example = tokenizer_summ(\n",
        "                              [WHITESPACE_HANDLER(example_cluster)],\n",
        "                              return_tensors=\"pt\",\n",
        "                              padding=\"max_length\",\n",
        "                              truncation=True\n",
        "                          ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "OAfEt4BU-ERE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   259, 167667,  40178,  ...,  30770,   1998,      1]],\n",
              "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "jgFcC-EI-eUB"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenized_example[\"input_ids\"]\n",
        "# input_ids = tokenized_example[\"input_ids\"].squeeze(dim=0) NOP,expects the unsqueexed dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5_KUYMu-kSn"
      },
      "outputs": [],
      "source": [
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "At4p5Mn8_pMP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5677"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY34ss9r9W-P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\Desktop\\envs\\.council-rag\\.council-rag\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:695: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0.6` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "output = model_summ.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=300,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=1) # if it is too slow, adjust num_beams and max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPFNUWGB-8Mp"
      },
      "outputs": [],
      "source": [
        "output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBfLlqnD-M6b"
      },
      "outputs": [],
      "source": [
        "summary = tokenizer_summ.decode(\n",
        "    output[0],\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSHTZ2Th9o3X"
      },
      "outputs": [],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKovfmQhAh53"
      },
      "source": [
        "### For the clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE3clzofFqwl"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMOBna6_5eFS"
      },
      "outputs": [],
      "source": [
        "def generate_summary(concat_text):\n",
        "\n",
        "  WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
        "\n",
        "  tokenized_example = tokenizer_summ(\n",
        "                              [WHITESPACE_HANDLER(concat_text)],\n",
        "                              return_tensors=\"pt\",\n",
        "                              padding=\"max_length\",\n",
        "                              truncation=True).to(device)\n",
        "\n",
        "  input_ids = tokenized_example[\"input_ids\"]\n",
        "\n",
        "  model_summ.eval()\n",
        "  with autocast(\"cuda\"):\n",
        "    summary_embedding_output = model_summ.generate(\n",
        "                                              input_ids=input_ids,\n",
        "                                              max_length=1000,\n",
        "                                              no_repeat_ngram_size=2,\n",
        "                                              num_beams=4) # if it is too slow, adjust num_beams and max_len\n",
        "\n",
        "  summary_decoded = tokenizer_summ.decode(\n",
        "                                    summary_embedding_output[0],\n",
        "                                    skip_special_tokens=True,\n",
        "                                    clean_up_tokenization_spaces=False)\n",
        "\n",
        "  torch.cuda.empty_cache() # Careful with running out of memory\n",
        "\n",
        "  return summary_embedding_output.detach().cpu().numpy(), summary_decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT5TmgOkEZBj"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RmBpsqmDgES"
      },
      "outputs": [],
      "source": [
        "def process_cluster(cluster, cluster_aggregates=cluster_aggregates):\n",
        "\n",
        "  print(\"Procesing cluster \", cluster+1)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  cluster_aggregates[cluster][\"broader_representations\"] = {}\n",
        "\n",
        "  concat_text = \" \".join(cluster_aggregates[cluster][\"texts\"])\n",
        "  cluster_aggregates[cluster][\"broader_representations\"][\"concat_text\"] = concat_text\n",
        "\n",
        "\n",
        "  cluster_embeddings = compute_norm_embeddings(concat_text)\n",
        "  cluster_aggregates[cluster][\"broader_representations\"][\"cluster_sentence_embeddings\"] = cluster_embeddings[0] # taking out the extra unnecesary dimension\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  summary_embedding_output, summary_decoded = generate_summary(concat_text)\n",
        "  cluster_aggregates[cluster][\"broader_representations\"][\"cluster_summary_embedding\"] = summary_embedding_output\n",
        "  cluster_aggregates[cluster][\"broader_representations\"][\"cluster_summary_decoded\"] = summary_decoded\n",
        "\n",
        "  return cluster_aggregates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aapNTjqsFXs7"
      },
      "outputs": [],
      "source": [
        "for cluster in list(cluster_aggregates.keys()):\n",
        "  cluster_aggregates = process_cluster(cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of12WNBcWAj0"
      },
      "outputs": [],
      "source": [
        "cluster_aggregates[1][\"broader_representations\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5iE6NkocBDS"
      },
      "outputs": [],
      "source": [
        "cluster_aggregates[1][\"broader_representations\"][\"cluster_summary_decoded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TET1QZvihmSF"
      },
      "outputs": [],
      "source": [
        "pprint(cluster_aggregates[1][\"broader_representations\"][\"concat_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS5NuQk_choX"
      },
      "outputs": [],
      "source": [
        "cluster_aggregates[0][\"broader_representations\"][\"cluster_summary_decoded\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".council-rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
