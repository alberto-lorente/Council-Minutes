{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_md_to_text.txt\", \"r\", encoding=\"latin-1\") as f: # TO DO: check proper encoding for .md files\n",
    "    markdown_example = f.read()\n",
    "\n",
    "with open(\"example.pdf\", \"rb\") as f:\n",
    "    pdf = f.read()\n",
    "\n",
    "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
    "    hf_token = f.read()\n",
    "\n",
    "with open(\"GROQ_KEY.txt\", \"r\") as f:\n",
    "    groq_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alberto-lorente\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder, whoami\n",
    "\n",
    "HfFolder.save_token(hf_token)\n",
    "print(whoami()[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda available\")\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"example.pdf\"\n",
    "\n",
    "base_prompt=\"\"\"CONTEXTE\n",
    "L'image suivante contient une page et un tableau. \n",
    "\n",
    "TÂCHE\n",
    "Décrivez le tableau et le contenu de la page en accordant une attention particulière au contexte qui l'entoure, qu'il s'agisse de budgets, de dates, d'élections, d'agendas, de projets futurs ou de sujets connexes. \n",
    "\n",
    "FORMAT DE LA RÉPONSE\n",
    "Votre réponse doit être aussi détaillée que possible. \n",
    "Votre résultat doit être la description du tableau directement.\n",
    "La langue de votre réponse est le français\"\"\"\n",
    "\n",
    "\n",
    "summary_prompt = \"\"\"Il s'agit d'un texte concernant un projet de géothermie :\n",
    "TEXTE: \n",
    "{}\n",
    "\n",
    "TÂCHE:\n",
    "Make a one page summary paying special attention to all the administrative matters like budgets, plans, actions to take in the future, organizational and hierarchical charts, announcements, meetings, contacts, elections, reports and all the related topics to these.\n",
    "\n",
    "OUTPUT:\n",
    "Publier directement le résumé.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def unload_cuda():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "unload_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from council_rag.preprocessing import preprocess_markdown_text\n",
    "from council_rag.data_transformations import process_tables, summarize_clusters\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "paragraphs_list, clusters_dict, model = preprocess_markdown_text(markdown_example,\n",
    "                                                        model_id =\"Jaume/gemma-2b-embeddings\", \n",
    "                                                        spacy_model=\"fr_core_news_sm\", \n",
    "                                                        n_sents_per_para=8,\n",
    "                                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unload_cuda()\n",
    "processed_tables = process_tables(pdf_path, \n",
    "                                base_prompt, \n",
    "                                groq_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cluster_0', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6', 'cluster_7'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.375812216599781\n"
     ]
    }
   ],
   "source": [
    "unload_cuda()\n",
    "clusters_dict = summarize_clusters(clusters_dict, \n",
    "                                    summary_prompt, \n",
    "                                    groq_token, \n",
    "                                    model=\"gemma2-9b-it\", \n",
    "                                    token_limit=14000, \n",
    "                                    sleep_time=60)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we are going to query are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraphs_dict \n",
    "# processed_tables\n",
    "# clusters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting some info that we won't need and turning the cluster dict into a list to match the paragraphs list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del paragraphs_list[0][\"para_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_list = list(clusters_dict.values())\n",
    "i = 0\n",
    "while i < len(clusters_list):\n",
    "    clusters_list[i][\"cluster\"] = i\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the embedding model and setting up the index and vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the embedding to pass it to the index\n",
    "shape_emb = embedding_model.encode(\"Hello World!\")\n",
    "emd_dims =  shape_emb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# init the intex\n",
    "index = faiss.IndexFlatL2(emd_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# creating the vector store\n",
    "vector_store = FAISS(embedding_model, \n",
    "                    index, \n",
    "                    InMemoryDocstore({}), \n",
    "                    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['para_indexes', 'union_paras', 'cluster_summary', 'cluster'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_list[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing all the information we have collected so far into Document objects that will be fed into the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paras = [] # to process into smaller chunks\n",
    "cluster_summ_docs = [] # filled with the cluster summaries langchain doc type\n",
    "\n",
    "for cluster in clusters_list:\n",
    "    \n",
    "    cluster_para = cluster[\"union_paras\"]\n",
    "    cluster_summ = cluster[\"cluster_summary\"]\n",
    "    \n",
    "    cluster_paras.append(cluster_para)\n",
    "    cluster_summ_docs.append(Document(page_content=cluster_summ, metadata={\"cluster\": cluster[\"cluster\"],\n",
    "                                                                            \"type\": \"summary\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=450, \n",
    "                                        chunk_overlap=35,\n",
    "                                        length_function=len,\n",
    "                                        is_separator_regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paras_docs = []\n",
    "for cluster_union in cluster_paras:\n",
    "    cluster_union_docs = splitter.split_text(cluster_union)\n",
    "    cluster_paras_docs.append(cluster_union_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_paras_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_chunks = []\n",
    "i = 0\n",
    "while i < len(cluster_paras_docs):  \n",
    "    curr_cluster = cluster_paras_docs[i]\n",
    "    for cluster_chunk in curr_cluster:\n",
    "        cluster_chunks.append(Document(page_content=cluster_chunk, metadata={\"cluster\": i,\n",
    "                                                                                \"type\": \"cluster_chunk\"}))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_table_chunks = []\n",
    "table_descriptions_chunks = []\n",
    "html_tables_chunks = []\n",
    "\n",
    "for table in processed_tables:\n",
    "    augmented_chunk = table[\"table_augmented_context\"]\n",
    "    augmented_table_chunks.append(Document(page_content=augmented_chunk, metadata={\"type\": \"augmented_table\"}))\n",
    "    \n",
    "    description_chunk = table[\"table_context\"]\n",
    "    table_descriptions_chunks.append(Document(page_content=description_chunk, metadata={\"type\": \"description_table\"}))\n",
    "    \n",
    "    html_chunk = table[\"table_html\"]\n",
    "    html_tables_chunks.append(Document(page_content=html_chunk, metadata={\"type\": \"html_table\"}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we have:\n",
    "\n",
    "- The individual text chunks.\n",
    "- The clusters summaries chunks.\n",
    "- The augmented table chunks.\n",
    "- The table descriptions chunks.\n",
    "- The html tables chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'cluster': 0, 'type': 'cluster_chunk'}, page_content=\"Rue des Vernes à Roanne\\n\\n\\n\\n # PROCES VERBAL\\n\\n\\n\\n L'an deux mille vingt et un, le 28 octobre à 18 h 00, les conseillers communautaires de Roannais Agglomération, se sont réunis à l\\x92Espace Chorum \\x96 Halle Vacheresse \\x96 Rue des Vernes à Roanne.\\n\\n\\n\\nLa convocation de tous les conseillers a été faite le 22 octobre 2021, dans les formes et délais prescrits par la loi, par Yves Nicolin, Président.\\n\\n\\n\\n # Etaient présents :\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'cluster': 0, 'type': 'summary'}, page_content='## Résumé du Procès-Verbal des Conseillers Communautaires de Roannais Agglomération \\n\\n**Date:** 28 octobre 2021\\n\\n**Lieu:** Espace Chorum - Halle Vacheresse - Rue des Vernes à Roanne\\n\\n**Présidence:** Yves Nicolin\\n\\nCe procès-verbal résume les décisions prises lors de la réunion du conseil communal de Roannais Agglomération le 28 octobre 2021. \\n\\n**Permissions et Conventions:**\\n\\n* **Droit de chasse:** La Fédération Départementale des Chasseurs de la Loire a obtenu un droit de chasse pédagogique sur le site Domaine des Grands Murcins. Ce droit est limité au grand gibier et aux espèces nuisibles, sans agrainage.\\n* **Construction Bâtiment d\\'Enseignement Supérieur:** Un avenant au contrat du lot 10  \"Serrurerie\" concernant les travaux de construction d\\'un Bâtiment d\\'Enseignement Supérieur sur le Campus Mendes France à Roanne (phase 2) a été approuvé avec la société ROCHE.\\n* **Avenant Spectacle \"BoOm\":**  L\\'avenant au contrat de cession du spectacle \"BoOm\" avec la compagnie \"Entre Eux Deux Rives\" a été approuvé.\\n\\n**Occupations de bâtiments:**\\n\\n*  La société SUPERBE AILE FORMATION obtient l\\'occupation du bâtiment \"Fox - Trot\" situé sur le site aéroportuaire de Roanne-Bois de Pouilly.\\n\\n\\n**Subventions:**\\n\\n*  Une subvention de 5 500 € est attribuée à l\\'association \"Vignobles Forez Roannais, Aux Racines de la Loire\" pour le territoire du vignoble Roannais.\\n\\n**Conventions de prestation de services:** \\n\\n*  L\\'avenant n°1 aux conventions de prestation de services avec les communes d\\'Ambierle, Mably, OPHEOR, Ouches, Pouilly-les-Nonains, Roannaise de l\\'Eau, Renaison, Riorges, Saint-Martin-d\\'Estreaux, Saint-Romain-la-Motte, Saint-Alban-les-Eaux, Saint-André-d\\'Apchon et Villerest a été approuvé. Ces conventions prennent fin le 31 décembre 2021.\\n\\n**(Important à noter que le procès-verbal ne fournit pas d\\'informations sur les plans d\\'aménagement, les budgets détaillés, les organisations internes, les prochains défis, les rapports financiers, les contacts spécifiques ou les résultats des élections.)**\\n\\n\\n\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_summ_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'type': 'augmented_table'}, page_content='Cette page et le tableau sont l\\'univers de la contestation politique issue du mouvement municipaliste breton. Il est à noter que l\\'ensemble des informations, lorsqu\\'il les connaissait, ou les prenait pour réelle, se révèle être erroné ou faux.\\n\\nLa suite de la réponse se trouve dans l\\'encadré \"SITUATION DE LA PAGE\".\\n    \\nTableau au format html:\\n\\n<table>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Absents\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Ni pouvoir\\n   <br/>\\n   Ni suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Pouvoir donné à…\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Marc Ambroise\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Laurence Boyer\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-France Catheland\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Muriel Marcellin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Chambost\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Clotilde Robin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Aimé Combaret\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Laure Dana Burnichon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Edmond Bourgeon\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   -\\n   <br/>\\n   Jean-Marc Detour\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Catherine Brun\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Daniel Fréchet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Lucien Murzi\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Quentin Guillermin\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Paul Heyberger\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christelle Lattat\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Franck Maupetit\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Annie Gerenton\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Patrick Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Nabih Nejjar\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Gilles Passot\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Fabien Lambert\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marcel Peuillon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Didier Prunet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christian Dupuis\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Vickie Redeuilh\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Hélène Lapalus\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Hélène Riamon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Denis Vanhecke\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Corinne Troncy\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Maryvonne Loughraieb\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Isabelle Valcourt\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Luc Mardeuil\\n  </td>\\n </tr>\\n</table>')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_table_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'type': 'description_table'}, page_content='Cette page et le tableau sont l\\'univers de la contestation politique issue du mouvement municipaliste breton. Il est à noter que l\\'ensemble des informations, lorsqu\\'il les connaissait, ou les prenait pour réelle, se révèle être erroné ou faux.\\n\\nLa suite de la réponse se trouve dans l\\'encadré \"SITUATION DE LA PAGE\".')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_descriptions_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'type': 'html_table'}, page_content='Cette page et le tableau sont l\\'univers de la contestation politique issue du mouvement municipaliste breton. Il est à noter que l\\'ensemble des informations, lorsqu\\'il les connaissait, ou les prenait pour réelle, se révèle être erroné ou faux.\\n\\nLa suite de la réponse se trouve dans l\\'encadré \"SITUATION DE LA PAGE\".\\n    \\nTableau au format html:\\n\\n<table>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Absents\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Ni pouvoir\\n   <br/>\\n   Ni suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Suppléant\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Pouvoir donné à…\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Marc Ambroise\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Laurence Boyer\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-France Catheland\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Muriel Marcellin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Yves Chambost\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Clotilde Robin\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Aimé Combaret\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Laure Dana Burnichon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Edmond Bourgeon\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   -\\n   <br/>\\n   Jean-Marc Detour\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Catherine Brun\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Daniel Fréchet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Lucien Murzi\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Quentin Guillermin\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Paul Heyberger\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christelle Lattat\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Franck Maupetit\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Annie Gerenton\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Patrick Meunier\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Nabih Nejjar\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Gilles Passot\\n   <br/>\\n   (arrivé en cours de séance)\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Fabien Lambert\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marcel Peuillon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   X\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Didier Prunet\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Christian Dupuis\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Vickie Redeuilh\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Hélène Lapalus\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Marie-Hélène Riamon\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Denis Vanhecke\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Corinne Troncy\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Maryvonne Loughraieb\\n  </td>\\n </tr>\\n <tr>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Isabelle Valcourt\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n  </td>\\n  <td colspan=\"1\" rowspan=\"1\">\\n   Jean-Luc Mardeuil\\n  </td>\\n </tr>\\n</table>')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tables_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = cluster_chunks + cluster_summ_docs + augmented_table_chunks + table_descriptions_chunks + html_tables_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [i for i in range(len(all_docs))]\n",
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "51\n",
      "77\n",
      "4\n",
      "74\n",
      "10\n",
      "23\n",
      "46\n",
      "58\n",
      "55\n",
      "49\n",
      "18\n",
      "70\n",
      "71\n",
      "55\n",
      "62\n",
      "35\n",
      "59\n",
      "72\n",
      "60\n",
      "30\n",
      "65\n",
      "6\n",
      "55\n",
      "36\n",
      "61\n",
      "32\n",
      "61\n",
      "26\n",
      "54\n",
      "64\n",
      "43\n",
      "65\n",
      "64\n",
      "69\n",
      "23\n",
      "65\n",
      "60\n",
      "67\n",
      "40\n",
      "62\n",
      "63\n",
      "50\n",
      "59\n",
      "41\n",
      "61\n",
      "22\n",
      "58\n",
      "37\n",
      "42\n",
      "54\n",
      "44\n",
      "69\n",
      "69\n",
      "67\n",
      "69\n",
      "47\n",
      "46\n",
      "63\n",
      "38\n",
      "34\n",
      "57\n",
      "51\n",
      "54\n",
      "53\n",
      "46\n",
      "36\n",
      "43\n",
      "70\n",
      "42\n",
      "67\n",
      "65\n",
      "73\n",
      "29\n",
      "76\n",
      "37\n",
      "72\n",
      "68\n",
      "64\n",
      "74\n",
      "36\n",
      "63\n",
      "51\n",
      "61\n",
      "48\n",
      "64\n",
      "63\n",
      "71\n",
      "70\n",
      "52\n",
      "38\n",
      "60\n",
      "51\n",
      "45\n",
      "57\n",
      "59\n",
      "62\n",
      "56\n",
      "32\n",
      "54\n",
      "73\n",
      "28\n",
      "63\n",
      "50\n",
      "66\n",
      "62\n",
      "68\n",
      "79\n",
      "36\n",
      "47\n",
      "65\n",
      "76\n",
      "39\n",
      "81\n",
      "54\n",
      "72\n",
      "51\n",
      "75\n",
      "59\n",
      "65\n",
      "82\n",
      "62\n",
      "70\n",
      "65\n",
      "49\n",
      "66\n",
      "70\n",
      "60\n",
      "41\n",
      "64\n",
      "44\n",
      "42\n",
      "66\n",
      "70\n",
      "56\n",
      "26\n",
      "64\n",
      "10\n",
      "71\n",
      "55\n",
      "61\n",
      "63\n",
      "56\n",
      "65\n",
      "58\n",
      "59\n",
      "73\n",
      "14\n",
      "71\n",
      "25\n",
      "9\n",
      "65\n",
      "7\n",
      "74\n",
      "6\n",
      "48\n",
      "61\n",
      "35\n",
      "59\n",
      "56\n",
      "76\n",
      "57\n",
      "94\n",
      "63\n",
      "77\n",
      "80\n",
      "87\n",
      "86\n",
      "48\n",
      "78\n",
      "80\n",
      "71\n",
      "68\n",
      "70\n",
      "61\n",
      "4\n",
      "80\n",
      "85\n",
      "35\n",
      "81\n",
      "10\n",
      "51\n",
      "14\n",
      "76\n",
      "28\n",
      "55\n",
      "73\n",
      "30\n",
      "57\n",
      "77\n",
      "75\n",
      "17\n",
      "26\n",
      "71\n",
      "76\n",
      "82\n",
      "12\n",
      "273\n",
      "308\n",
      "1407\n",
      "278\n",
      "404\n",
      "1134\n",
      "269\n",
      "387\n",
      "806\n",
      "4238\n",
      "605\n",
      "718\n",
      "918\n",
      "478\n",
      "203\n",
      "453\n",
      "2194\n",
      "1180\n",
      "835\n",
      "1479\n",
      "3051\n",
      "809\n",
      "775\n",
      "1160\n",
      "280\n",
      "340\n",
      "813\n",
      "1403\n",
      "4719\n",
      "423\n",
      "376\n",
      "542\n",
      "906\n",
      "1437\n",
      "4198\n",
      "1049\n",
      "3209\n",
      "50\n",
      "4091\n",
      "294\n",
      "568\n",
      "726\n",
      "217\n",
      "88\n",
      "279\n",
      "868\n",
      "720\n",
      "319\n",
      "564\n",
      "911\n",
      "621\n",
      "433\n",
      "879\n",
      "106\n",
      "37\n",
      "457\n",
      "826\n",
      "4453\n",
      "12\n",
      "192\n",
      "439\n",
      "466\n",
      "634\n",
      "3885\n",
      "946\n",
      "3048\n",
      "806\n",
      "4238\n",
      "605\n",
      "718\n",
      "918\n",
      "478\n",
      "203\n",
      "453\n",
      "2194\n",
      "1180\n",
      "835\n",
      "1479\n",
      "3051\n",
      "809\n",
      "775\n",
      "1160\n",
      "280\n",
      "340\n",
      "813\n",
      "1403\n",
      "4719\n",
      "423\n",
      "376\n",
      "542\n",
      "906\n",
      "1437\n",
      "4198\n",
      "1049\n",
      "3209\n"
     ]
    }
   ],
   "source": [
    "# checking types of the docs\n",
    "for doc in all_docs:\n",
    "    # print(type(doc))\n",
    "    # print(doc.metadata)\n",
    "    # print(doc.page_content)\n",
    "    print(len(doc.page_content.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(vector_store.add_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council_rag.data_transformations.text_transformations import generate_groq_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_shorten_prompt=\"Résumez le texte suivant en moins de 1400 mots: {}. Output le résumé directement.\"\n",
    "for doc in all_docs:\n",
    "    if len(doc.page_content.split(\" \")) > 1500:\n",
    "        new_content = generate_groq_summary(summary_shorten_prompt, doc.page_content, groq_token, model=\"gemma2-9b-it\")\n",
    "        doc.page_content = new_content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# checking types of the docs\n",
    "for doc in all_docs:\n",
    "    # print(type(doc))\n",
    "    # print(doc.metadata)\n",
    "    # print(doc.page_content)\n",
    "    if len(doc.page_content.split(\" \")) > 1500:\n",
    "        # print(len(doc.page_content.split(\" \")))\n",
    "        # print(doc.page_content)\n",
    "        print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council_rag.preprocessing.preprocessing import compute_norm_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m unload_cuda()\n\u001b[1;32m----> 2\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_norm_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m all_docs]\n",
      "File \u001b[1;32mc:\\Users\\alber\\Desktop\\Council-Minutes\\Alberto Research\\RAGTOR\\council_rag\\preprocessing\\preprocessing.py:96\u001b[0m, in \u001b[0;36mcompute_norm_embeddings\u001b[1;34m(model, sentence)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_norm_embeddings\u001b[39m(model, sentence):\n\u001b[1;32m---> 96\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     unload_cuda()\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unload_cuda()\n",
    "all_embeddings = [compute_norm_embeddings(embedding_model, doc.page_content) for doc in all_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UP UNTIL THIS POINT, EVERYTHING IS PACKAGED MISSING THE ACTUAL POPULATING OF THE DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Get from Tunji's thingie\"\n",
    "\n",
    "results = vector_store.similarity_search(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"}, # put the clustering, etc here\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\") # this is how to get the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK WITH THE FIXED VECTOR STORE BEFORE PACKAGING INTO COUNCIL_RAG.RAG AND MAIN.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo to query the store in the right order\n",
    "def query_vector_store(vector_store, query):\n",
    "        # first search through the summaries\n",
    "        results_query_level_one = vector_store.similarity_search(\n",
    "                                                                query,\n",
    "                                                                k=1,\n",
    "                                                                filter={\"type\": \"summary\"}, \n",
    "                                                                )\n",
    "\n",
    "        cluster_level_one = results_query_level_one[0].metadata[\"cluster\"]\n",
    "\n",
    "        # now we search only in the cluster retrieved in the first step\n",
    "        results_query_level_two = vector_store.similarity_search(\n",
    "                                                        query,\n",
    "                                                        k=5,\n",
    "                                                        filter={\"cluster\": cluster_level_one,\n",
    "                                                                \"type\": \"cluster_chunk\"}, \n",
    "                                                        )\n",
    "        results_query_tables = vector_store.similarity_search(\n",
    "                                                        query,\n",
    "                                                        k=1,\n",
    "                                                        filter={\"type\": 'description_table'}, # {\"$in\": []} \n",
    "                                                        )\n",
    "        \n",
    "        relevant_facts = [sent_query_level_two.page_content for sent_query_level_two in results_query_level_two]\n",
    "        relevant_table = results_query_tables.page_content\n",
    "        \n",
    "        return relevant_facts, relevant_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_query_rag(query, relevant_facts, relevant_table):\n",
    "    \n",
    "    aug_prompt=\"\"\"\\nVoici quelques faits pertinents pour vous aider à répondre et una description du qui peut s'avérer utile. \n",
    "    Si la description du n'est pas utile, ignorez-le.\\n\"\"\"\n",
    "    \n",
    "    augmented_data_string = aug_prompt + \"\\n\".join(relevant_facts) + \"\\n\" + relevant_table\n",
    "    \n",
    "    formated_augmented_query = query.format(augmented_data_string) # the original query has to have a format string\n",
    "    # formated_augmented_query = query + augmented_data_string       # if that is not the case, we can do this instead\n",
    "    \n",
    "    return formated_augmented_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def final_query(query, model, groq_key):\n",
    "    \n",
    "    client = Groq(api_key=groq_key)\n",
    "    \n",
    "    messages = [\n",
    "                {\"role\": \"system\",\n",
    "                \"content\":  \"Vous êtes un assistant utile\" },\n",
    "                {\"role\": \"user\",\n",
    "                \"content\":  query}\n",
    "                ]\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(messages=messages, model=model)\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final fx to query our list of queries\n",
    "\n",
    "def query_multiple(list_of_queries, vector_store, model, groq_key):\n",
    "    \n",
    "    responses = []\n",
    "    for query in list_of_queries:\n",
    "        \n",
    "        relevant_facts, relevant_table = query_vector_store(vector_store, query)\n",
    "        formated_augmented_query = augment_query_rag(query, relevant_facts, relevant_table)\n",
    "        response = final_query(formated_augmented_query, model, groq_key)\n",
    "        responses.append(response)\n",
    "    \n",
    "    return responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
