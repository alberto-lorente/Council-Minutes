{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in /Users/tunji/.local/share/virtualenvs/council-minutes-1mY8XzjE/lib/python3.12/site-packages (2018.7.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implements a Binary Classifier to check if text concerns a geothermal project or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/html/parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "/usr/local/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/html/parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_geothermal = pd.read_csv('../dataset.csv')\n",
    "df_not_geothermal = pd.read_csv('../dataset-random.csv')\n",
    "\n",
    "# Load a random subset of the dataset for development\n",
    "# TODO: Load the entire dataset\n",
    "df_geothermal = df_geothermal.sample(200)\n",
    "df_not_geothermal = df_not_geothermal.sample(200)\n",
    "\n",
    "\n",
    "def extract_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_geothermal['extracted_text'] = df_geothermal['fulltext'].apply(extract_text)\n",
    "df_not_geothermal['extracted_text'] = df_not_geothermal['fulltext'].apply(extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a label to the data\n",
    "df_geothermal['label'] = 1\n",
    "df_not_geothermal['label'] = 0\n",
    "\n",
    "# Combine the datasets\n",
    "df = pd.concat([df_geothermal, df_not_geothermal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_documents(documents):\n",
    "    stop_words = get_stop_words('fr')\n",
    "    # Convert texts to TF-IDF features\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words=stop_words,\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    texts = documents.tolist()\n",
    "    return vectorizer, vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train classifier\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        33\n",
      "           1       0.91      0.94      0.92        31\n",
      "\n",
      "    accuracy                           0.92        64\n",
      "   macro avg       0.92      0.92      0.92        64\n",
      "weighted avg       0.92      0.92      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_geothermal_filter(documents, labels):\n",
    "    # Preprocess\n",
    "    vectorizer, X = preprocess_documents(documents)\n",
    "\n",
    "    # Train\n",
    "    classifier = train_classifier(X, labels)\n",
    "\n",
    "    # Create filter function\n",
    "    def filter_document(new_doc):\n",
    "        doc_vector = vectorizer.transform([new_doc])\n",
    "        return classifier.predict(doc_vector)[0]\n",
    "\n",
    "    return filter_document\n",
    "\n",
    "# Split df into training and testing data\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "filter_func = create_geothermal_filter(df_train['extracted_text'], df_train['label'])\n",
    "\n",
    "# Apply the filter to the test set\n",
    "df_test['predicted'] = df_test['extracted_text'].apply(filter_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  doc_id  predicted  label\n",
      "18407  35638/4771de8aecc7f92d2f4676ffcfbbd87353f0d017...          1      1\n",
      "451                       2719/37b27_vc5ltu3jsb46v15.pdf          0      0\n",
      "1481   2899/922a364ba232297cd39c5057a21e6d5e184f632a_...          1      1\n",
      "910         2694/2772a_221206_FLYER_PLAN_DECHETS_WEB.pdf          0      0\n",
      "12773  1928/b0fdf18ba81f63a57cfeefda4781d897fb216711_...          1      1\n",
      "...                                                  ...        ...    ...\n",
      "267    2401/b8f75_Budget%20primitif%20budget%20princi...          0      0\n",
      "735    3073/56ef8_declaration-dinstallation-dANC.2023...          0      0\n",
      "11441  6798/70ac5e6b7e382f1bfd5683ffa8fc8d7be8a149d5_...          0      1\n",
      "207                       3181/3cba0_AT-2023-MEB-064.pdf          0      0\n",
      "669    2646/e2749_ANNEXES-du-reglement-de-services-20...          0      0\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print, doc_id, predicted, label\n",
    "print(df_test[['doc_id', 'predicted', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "council-minutes-1mY8XzjE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
